[
  {
    "objectID": "resmindmap.html#mindmap",
    "href": "resmindmap.html#mindmap",
    "title": "Research proposal",
    "section": "MindMap",
    "text": "MindMap\n\nAdvanced Techniques for Multiperiod Multiobjective Portfolio Optimization in Agricultural Commodity Markets:\nCombining Volatility Modeling and Reinforcement Learning and Exploring Strategic Asset Allocation",
    "crumbs": [
      "About",
      "Intro",
      "Research proposal"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "presFAE.html",
    "href": "presFAE.html",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "",
    "text": "Mercado financeiro:\n\nÉ um ambiente dinâmico onde decisões baseadas em dados podem otimizar resultados.\n\nData driven decision making:\n\nComo tomar uma decisão econômica de maneira rápida, ótima e eficiente ?\n\n\n\n\n\n\n\n\nPor que Big Data é relevante ?\n\n\n\n\n\n\nVolume de Dados: A análise do mercado de commodities envolve um enorme volume de dados financeiros e econômicos que cresce rapidamente, especialmente considerando históricos de preços diários, transações e eventos externos que influenciam os mercados.\nVariabilidade e Velocidade: As séries de preços de commodities possuem mudanças rápidas e variações, exigindo a capacidade de processar e analisar dados em tempo hábil para garantir insights relevantes.\nAnálises em Profundidade: Necessidade de descobrir padrões ocultos que requerem recursos computacionais consideráveis para manipular e analisar um volume grande e complexo de dados."
  },
  {
    "objectID": "presFAE.html#introdução",
    "href": "presFAE.html#introdução",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "",
    "text": "Mercado financeiro:\n\nÉ um ambiente dinâmico onde decisões baseadas em dados podem otimizar resultados.\n\nData driven decision making:\n\nComo tomar uma decisão econômica de maneira rápida, ótima e eficiente ?\n\n\n\n\n\n\n\n\nPor que Big Data é relevante ?\n\n\n\n\n\n\nVolume de Dados: A análise do mercado de commodities envolve um enorme volume de dados financeiros e econômicos que cresce rapidamente, especialmente considerando históricos de preços diários, transações e eventos externos que influenciam os mercados.\nVariabilidade e Velocidade: As séries de preços de commodities possuem mudanças rápidas e variações, exigindo a capacidade de processar e analisar dados em tempo hábil para garantir insights relevantes.\nAnálises em Profundidade: Necessidade de descobrir padrões ocultos que requerem recursos computacionais consideráveis para manipular e analisar um volume grande e complexo de dados."
  },
  {
    "objectID": "presFAE.html#problemática-de-pesquisa",
    "href": "presFAE.html#problemática-de-pesquisa",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Problemática de Pesquisa",
    "text": "Problemática de Pesquisa\n\n\n\n\n\n\n\nSource: Data extraction from Yahoo!Finances API ploted by using Plotly"
  },
  {
    "objectID": "presFAE.html#problemática-de-pesquisa-1",
    "href": "presFAE.html#problemática-de-pesquisa-1",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Problemática de Pesquisa",
    "text": "Problemática de Pesquisa\n \n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuais as causas ou desencadeadores desses movimentos repentinos de inversão de tendência nas séries de preços ?\nÉ possível estimar/medir o quanto essas mudanças bruscas de tendência geram de impacto na economia e no mercado de commodities agrícolas ?\nComo podemos antecipar/prever o acontecimento dessas “quebras” nas séries temporais de preços no futuro ?\nPode-se otimizar o processo decisório de compra e venda de grãos recomendando as melhores alocações de portfólio de commodities em condições de risco e incerteza ?\nComo decidir ou facilitar o processo decisório humano dentro de um contexto de massivo volume e velocidade de informações ?\nQual o volume de dados ou tamanho de série histórica necessária pra construir um modelo eficiente ?"
  },
  {
    "objectID": "presFAE.html#teorias-de-base",
    "href": "presFAE.html#teorias-de-base",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Teorias de Base",
    "text": "Teorias de Base\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nÁrea de Ciência\nTeoria\nPensadores\n\n\n\n\nMicroeconomia\nTeoria da Demanda e do Consumidor\nWalrás, Pareto, Arrow, Debreu, Samuelson, Hicks\n\n\nMicroeconomia\nEstruturas de Mercado\nPorter, Chamberlin, Joan Robinson, Bain\n\n\nMicroeconomia\nFinanças Comportamentais\nDaniel Kahneman, Amos Tversky, Robert Shiller\n\n\nMicroeconomia\nEficiência de Mercado\nEugene Fama, Fischer Black e Myron Scholes, Jensen\n\n\nMicroeconomia\nTeoria do Portfólio\nHarry Markowitz, Milton Friedman, Keynes\n\n\nFinanças\nTeoria dos Ciclos Financeiros\nHyman Minsky, Irving Fischer, Joseph Schumpeter e Kondratiev\n\n\nFinanças\nTeoria do Mais Tolo (ou Teoria do Toque de Midas Reverso)\nJohn Kenneth Galbraith, Nassim Taleb\n\n\nEconometria Financeira\nBayesian GARCH with Markov Regime Switching\nDavid Ardia, Robert Engle, Tim Bollerslev, Gary Koop\n\n\nMacroeconomia\nTeoria da Formação das Expectativas\nRobert Lucas, Milton Friedman, Edmund Phelps, Franco Modigliani\n\n\nNeuroeconomia\nTeoria da Hipótese da Antecipação de Recompensa\nWolfram Schultz, Antonio Rangel, Paul Glimcher\n\n\nMicroeconomia\nTeoria da Seleção Adversa\nGeorge Akerlof, Michael Spence, Stiglitz\n\n\nComplexidade (Física de redes)\nSistemas Dinâmicos Adpatativos não-lineares\nArthur Ávila, Brian Arthur, Robert May"
  },
  {
    "objectID": "presFAE.html#hipóteses-científicas",
    "href": "presFAE.html#hipóteses-científicas",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Hipóteses Científicas",
    "text": "Hipóteses Científicas\n\n\n\n\n\n\n\nInsights\n\n\n\n\nVolatility Clustering e mudanças estruturais\n\n \n\nAnálise de Intervenção Causal em Séries Temporais nas quebras e “efeito disseminação”\n\n \n\nDesenvolvimentos do modelo de otimização de portfolio de Markowitz (CAPM, B&S, Merton, Black-Litterman …)\n\n \n\nMúltiplos Objetivos variando conforme o contexto de mercado e as expectativas percebidas (risco e incerteza)"
  },
  {
    "objectID": "presFAE.html#justificativa-e-relevância",
    "href": "presFAE.html#justificativa-e-relevância",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Justificativa e relevância",
    "text": "Justificativa e relevância\n \n\n\n\n\n\n\n\nContribuições teóricas\n\n\n\n\n\n\nIdentificação dos drivers dos preços auxilia na investigação da causa dos movimentos repentinos nas séries de preços (Teoria da Demanda do Consumidor, Estruturas de Mercado e Teoria do Portfólio [motivo transação, especulação ou precaução]) pode ser utilizada em conjunto com a técnica Econométrica de Análise de Intervenção em Séries Temporais [Angrist e Imbens, Brodersen et. alli (2015)] para avaliar seu impacto causal na série de preço estudada;\nA Teoria dos Ciclos Financeiros ajuda a compreender em qual contexto econômico a disseminação de efeito econômico-financeiro nocivo ou positivo está inserida frente a quebra repentina da tendência da trajetória de preços de alimentos (commodities)\nO uso das técnicas pertinentes dentro da teoria da Econometria Financeira com o uso do modelo Bayesiano GARCH com mudanças de regime markovianos se mostra aderente à realidade dos dados e condizente com os últimos desenvolvimentos teóricos a respeito do fenômeno da dinâmica complexa dos preços dessas commodities;\nA teoria de alocação de portfólio desde Markowitz pode ser melhor elaborada combinando as ferramentas de otimização multiobjetivo multiperíodo de maneira dinâmica em consonância com modelos econométricos que consigam incorporar com maior clareza a “incerteza” percebida pelos players de mercado na sua aferição de risco x retorno. Assim, os processos decisórios de compra e venda em momentos oportunos se tornariam mais claros."
  },
  {
    "objectID": "presFAE.html#big-data-na-análise-de-commodities",
    "href": "presFAE.html#big-data-na-análise-de-commodities",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Big Data na Análise de Commodities",
    "text": "Big Data na Análise de Commodities\n \n\n\n\n\n\n\n\nAmostragem de Dados Significativa\n\n\n\n\nEstratégia de Amostragem: Utilizar amostragem estratificada para garantir que a variabilidade ao longo do tempo seja capturada de forma adequada (como choques econômicos ou eventos climáticos que impactam os preços).\nRedução de Dimensionalidade: Utilizar técnicas de PCA (Principal Component Analysis) para reduzir o número de variáveis sem perder informações importantes, permitindo uma análise mais eficiente dos dados.\nUso de Dados Representativos: A seleção de um subconjunto representativo de dados pode ser feita para capturar as tendências de mercado de diferentes períodos, garantindo que os insights gerados sejam válidos e aplicáveis."
  },
  {
    "objectID": "presFAE.html#big-data-na-análise-de-commodities-1",
    "href": "presFAE.html#big-data-na-análise-de-commodities-1",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Big Data na Análise de Commodities",
    "text": "Big Data na Análise de Commodities\n \n\n\n\n\n\n\n\nFerramentas e Bibliotecas Utilizadas (alguns exemplos)\n\n\n\nPython:\n\nPySpark: Uma ferramenta poderosa para processamento distribuído e análise de grandes volumes de dados, ideal para trabalhar com dados de commodities de históricos extensivos.\nDask: Alternativa à biblioteca Pandas, que facilita o processamento de grandes datasets que não cabem na memória. Dask permite a execução de operações paralelas, otimizando análises.\n\nR:\n\nsparklyr e SparkR: Integração do Spark no ambiente R, possibilitando o processamento distribuído e a manipulação eficiente de datasets gigantescos, com foco em análises financeiras.\nvroom e data.table: Utilizadas para leitura rápida e manipulação de grandes volumes de dados armazenados em arquivos CSV, permitindo o carregamento de arquivos grandes em poucos segundos.\n\n*Existem algumas outras pra R e Python que poderiam ser mencionadas aqui, mas por questões de parcimônia limitaremos a pequenos exemplos."
  },
  {
    "objectID": "presFAE.html#big-data-com-r",
    "href": "presFAE.html#big-data-com-r",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Big Data com R",
    "text": "Big Data com R\n \n\nAnálise de Commodities com sparklyr e vroom\n\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(vroom)\n\n# Conectar ao Spark\nsc &lt;- spark_connect(master = \"local[*]\") # Você pode rodar também no Databricks, Azure, AWS, Google Colab...\n\n# Ler grandes volumes de dados usando vroom\nfile_list &lt;- list.files(\"data\", pattern = \"*_data.csv\", full.names = TRUE)\ncombined_data &lt;- vroom(file_list, col_types = list(\n  Date = col_date(),\n  Open = col_double(),\n  High = col_double(),\n  Low = col_double(),\n  Close = col_double(),\n  Volume = col_double(),\n  Adj.Close = col_double(),\n  Ticker = col_character()\n))\n\n# Copiar os dados para o Spark\nspark_data &lt;- copy_to(sc, combined_data, \"commodities_data\", overwrite = TRUE)\n\n# Executar análise no Spark: calcular a média de fechamento ajustado por commodity\naverage_close &lt;- spark_data |&gt;\n  group_by(Ticker) |&gt;\n  summarise(Average_Close = mean(Adj.Close, na.rm = TRUE)) |&gt;\n  collect()\n\nprint(average_close)\n\n# Desconectar do Spark\nspark_disconnect(sc)"
  },
  {
    "objectID": "presFAE.html#big-data-com-python",
    "href": "presFAE.html#big-data-com-python",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Big Data com Python",
    "text": "Big Data com Python\n \n\nAnálise de Commodities com PySpark e Dask\n\nfrom pyspark.sql import SparkSession\nimport dask.dataframe as dd\n\n# Inicializar a sessão Spark\nspark = SparkSession.builder.master(\"local\").appName(\"Commodities Analysis\").getOrCreate()\n\n# Carregar dados grandes de commodities usando Dask\nfile_list = [\"data/ZC=F_data.csv\", \"data/ZO=F_data.csv\", \"data/KE=F_data.csv\"]\ndf_dask = dd.read_csv(file_list)\n\n# Converter o DataFrame Dask para Spark\ndf_spark = spark.createDataFrame(df_dask.compute())\n\n# Analisar os dados no Spark\ndf_spark.createOrReplaceTempView(\"commodities_data\")\nresult = spark.sql(\"SELECT Ticker, AVG(Adj_Close) as Average_Close FROM commodities_data GROUP BY Ticker\")\nresult.show()\n\n# Finalizar a sessão Spark\nspark.stop()"
  },
  {
    "objectID": "presFAE.html#exercícios-rápidos",
    "href": "presFAE.html#exercícios-rápidos",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Exercícios rápidos",
    "text": "Exercícios rápidos\n \n\n\nA partir das instruções contidas no post em como ler com o Sparklyr Big Data localmente, leia e processe usando o pacote do R sparklyr localmente o conjunto de dados vix-daily.csv (menor) e o .rds gbt-model-responses. 1.a) Agora leia eles usando o Dask (Python), data.table e vroom (R) localmente e as reporte num documento Quarto\nComo você analisaria o conjunto de dados de hipotecas (mortgages) ou outra fonte aqui no repo ? Ele contém dados fictícios ou anonimizados sobre empréstimos imobiliários, fornecendo informações que podem ser usadas para estudar padrões de empréstimos, análise de risco de crédito ou previsões de inadimplência. Elabore uma proposta de projeto a partir desse dataset em R ou em Python utilizando o report utilizando o quarto.org pra ganhar velocidade!\nE quando o Spark, data.table, vroom, Dask e etc. não derem mais conta do recado ? Pesquise alternativas e sugira algumas estratégias pra lidar com grandes volumes de dados e modelá-los ! Lembre-se de citar as fontes, pacotes, métodos e referências necessárias. (Algumas sugestões de uso de dados brasileiros via extração por API em Repo Doc. gitHub)\nExpanda o exemplo do portfólio de commodities, utilizando uma extração de séries temporais mais longas no tempo, inserindo mais ativos no portfólio (utilize o pacote do R quantmod ou do Python yfinance) utilizando a sintaxe do Spark e experimente os pacotes do R úteis pra isso como a sintaxe do data.table ou a leitura do conjunto de dados com o vroom localmente. Como poderemos analisar tendências desses dados utilizando um modelo de médias móveis simples ?"
  },
  {
    "objectID": "presFAE.html#mais-informações-e-referências",
    "href": "presFAE.html#mais-informações-e-referências",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Mais informações e referências",
    "text": "Mais informações e referências\n \n\n\n\n\n\n\n\n\nEnvie esses reports nos formatos .qmd e .html num arquivo .zip para rodrigo.ozon@fae.edu.br\nPrazo de envio (1 e 2 até o final da próxima semana) e 3 e 4 (até o final da semana subsequente)\nMaiores detalhes a respeito de fontes, referências, recomendações de cursos online, pacotes e libs, consulte por favor o Plano de Aula de hoje"
  },
  {
    "objectID": "presFAE.html#obrigado",
    "href": "presFAE.html#obrigado",
    "title": "Análise de Dados do Mercado Financeiro:",
    "section": "Obrigado!",
    "text": "Obrigado!\n \n\n\n\n\n\n\n\nRodrigo Hermont Ozon\n\n\n\n\\(\\Rightarrow\\) Agradecimentos à todos os membros da banca examinadora e demais ouvintes:\n\nMeu perfil no Google Scholar\nMeu CV Lattes\nMeu site com posts, tutoriais e artigos\nMeu perfil no LinkeDin\n\n\n\n \n \n\n\n\n\"Situations emerge in the process of creative destruction in which many firms may have to perish that nevertheless would be able to live on vigorously and usefully if they could weather a particular storm.\n\n[... Capitalism requires] the perennial gale of Creative Destruction.\" Schumpeter, Joseph A. (1994) [1942]. Capitalism, Socialism and Democracy. London: Routledge. pp. 82–83. ISBN 978-0-415-10762-4. Retrieved 23 November 2011."
  },
  {
    "objectID": "interactivemindmap.html",
    "href": "interactivemindmap.html",
    "title": "Interactive full mindmap",
    "section": "",
    "text": "Follow the link he"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About the PIBIC and PIBITI Jr.",
    "section": "",
    "text": "About the PIBIC and PIBITI Jr.\nThis project is carried out as part of a research initiation (PIBIC and PIBITI Jr.) at PUCPR, focusing on advanced forecasting and optimization techniques applied to agriculture.\n\nRodrigoRicardoGabrielly\n\n\n  \n\nAdvisor/Researcher\n\nEconomist and Msc. in Economic Development (UFPR, 2008 & 2010), PhD Candidate at PPGEPS/PUCPR (2022-2026)\n\n\n\n\n\n\n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n\n    \n    \n        \n    \n    \n    \n    \n        \n    \n\n\n  \n\n\n\n  \n\nComputer Science Researcher at PUCPR\n\nUndergratuate student \\(\\Rightarrow\\) Computer Science Website at PUCPR\n\n\n\n\n\n\n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n\n  \n\n\n  \n\nAdventist College student\n\nLink for the College institution \\(\\Rightarrow\\) Colégio Adventista Pinhais",
    "crumbs": [
      "About",
      "Intro",
      "About the PIBIC and PIBITI Jr."
    ]
  },
  {
    "objectID": "mindmap.html",
    "href": "mindmap.html",
    "title": "The Research Mindmap",
    "section": "",
    "text": "Overview\nThe following flowchart illustrates the research workflow, detailing the key methodologies and how they are interconnected. It starts from the problem identification and moves through volatility modeling, predictive modeling, and optimization processes.\n\n\n\n\n\n\n\n\n\n\n\nResearch Proposal: Advanced Techniques for Multiperiod Multiobjective Portfolio Optimization in Commodity Markets\nThis research addresses the significant challenge of modeling and forecasting agricultural commodity prices, which are subject to high volatility and complex dynamics. Agricultural markets are highly sensitive to external factors such as climatic changes, geopolitical events, and supply-demand imbalances, making accurate forecasting and risk management difficult for investors and policymakers.\n\nKey Components of the Research:\n\nVolatility Modeling Using GAMLSS and MSGARCH:\n\nGAMLSS: This technique provides a nuanced understanding of the distributional characteristics of commodity returns, capturing the probabilistic behaviors that traditional models often overlook.\nMSGARCH: By implementing the Markov-Switching GARCH model, the research captures regime shifts in volatility, which are common in commodities due to external shocks and systemic changes.\n\nMulti-Objective Portfolio Optimization:\n\nThis step involves developing a multi-objective optimization framework using evolutionary algorithms such as NSGA-II and Differential Evolution (DEOptim). These algorithms help optimize portfolio allocation by balancing risk, return, and diversification, particularly for portfolios with high-volatility assets like agricultural commodities.\n\nReinforcement Learning for Portfolio Management:\n\nThe research also introduces Reinforcement Learning (RL) methods, such as Q-Learning and K-Bandit algorithms, to adaptively manage portfolio strategies. These techniques are particularly suited for dynamic portfolio management, allowing strategies to evolve as market conditions change.\n\n\n\n\nContribution to Knowledge:\nThe research’s innovative contribution lies in combining these advanced econometric and machine learning techniques to tackle the unique challenges of commodity markets. It offers a comprehensive methodological framework that improves the modeling and forecasting of volatility and returns in agricultural commodities. This work enhances portfolio optimization strategies, offering practical applications for financial markets by providing tools that help portfolio managers make informed, data-driven decisions in the face of volatile market conditions.\nFinal Objective: The primary goal of this research is to develop robust methods for volatility modeling and portfolio optimization that dynamically adapt to market conditions. This approach offers a significant advancement in both academic and professional fields by providing actionable insights for managing portfolios in volatile commodity markets.\nHere we can see an much more complete and interactive mindmap: (if the HTML doesn´t work, see the pic below)",
    "crumbs": [
      "About",
      "Intro",
      "The Research Mindmap"
    ]
  }
]