[
  {
    "objectID": "publplan.html",
    "href": "publplan.html",
    "title": "Journals publication plan",
    "section": "",
    "text": "Abstract\n\n\n\nThe main idea here is to schedule the publication plan to be sended for specific indexed magazines, journals, periodicals and scientific research pairs.",
    "crumbs": [
      "About",
      "Intro",
      "Journals publication plan"
    ]
  },
  {
    "objectID": "publplan.html#possible-journals",
    "href": "publplan.html#possible-journals",
    "title": "Journals publication plan",
    "section": "Possible Journals",
    "text": "Possible Journals\n\nPaper 1\n\nPaper title: “Impact of Sentiment Analysis on the Volatility and Structural Breaks in Agricultural Commodity Prices” by Rodrigo Hermont Ozon and Ricardo Viana (see the publishing plan for this paper here at this presentation)\n\n\n\nAbstract:\nThis study explores the impact of sentiment analysis on the volatility and structural breaks in agricultural commodity prices. Agricultural markets are often subject to abrupt fluctuations and high volatility, making it essential for investors and policymakers to understand the factors driving these changes. Sentiment analysis, derived from news sources and social media, offers an additional layer of data that complements traditional econometric models, providing a broader understanding of market behavior. This research will utilize time series data of agricultural commodity prices and sentiment metrics obtained through natural language processing (NLP) tools applied to news data.\nThe proposed methods include the application of econometric models such as conditional volatility analysis (GARCH) and structural break models (e.g., the Bai-Perron model) to capture the effects of market sentiment on price fluctuations. Additionally, a multi-objective optimization model will be used to adjust agricultural commodity portfolios, accounting for the sentiment-driven volatility impact. Expected results include identifying a significant relationship between market sentiment and price variations, as well as validating an optimized approach to managing commodity portfolios, based on both sentiment data and volatility patterns.\nThis study will provide valuable insights for portfolio managers and investors, enabling them to incorporate sentiment indicators into their investment strategies and improve the forecasting of commodity market fluctuations. The relevance of this research lies in the growing need to understand how qualitative variables, such as market sentiment, affect agricultural commodity prices in the context of global economic uncertainties.\nKeyWords: Sentiment Analysis, Time Series, Volatility, Structural Breaks, Portfolio Optimization, Commodity Prices.\n\n\n\nJournal\nText Match Score (1 to 5)\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nJournal of Commodity Markets\n5\n4.3\n-\n60\n\n\nFinance Research Letters\n5\n11.1\n24%\n10\n\n\nEnergy Economics\n5\n10.8\n-\n30\n\n\nJournal of Business Research\n4\n11.2\n-\n12\n\n\nEconomic Modelling\n5\n5.8\n-\n18\n\n\nJournal of Banking and Finance\n5\n6.4\n25%\n40\n\n\nJournal of Behavioral and Experimental Finance\n4\n4.5\n-\n6\n\n\nEmerging Markets Review\n5\n4.1\n-\n30\n\n\nComputers and Electronics in Agriculture\n5\n7.6\n30%\n15\n\n\nInternational Economics\n4\n3.9\n-\n45\n\n\n\nSource: Elsevier Journal Finder Results\n\n\n\nPaper 2\n\nPaper title: “Ablation Study of a CNN+LSTM Architecture for Time Series Forecasting of Corn Price Returns” by Rodrigo Hermont Ozon\n\n\n\nAbstract:\nThis paper presents an ablation study of a hybrid CNN+LSTM architecture applied to the forecasting of logarithmic returns of corn prices. Different hyperparameter configurations are explored, including the addition/removal of layers, changes in loss functions, and variations in optimizers. Results are evaluated using metrics such as mean squared error (MSE), mean absolute percentage error (MAPE), and the coefficient of determination (\\(R^2\\)). The conclusions provide insights into the critical components of the architecture for modeling complex time series data.\nKeywords: Time Series, CNN+LSTM, Ablation Study, Price Forecasting, Artificial Neural Networks.\n\n\n\nJournal\nText Match Score\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nNeurocomputing\n5\n8.7\n30%\n45\n\n\nExpert Systems with Applications\n5\n12.2\n28%\n30\n\n\nJournal of Forecasting\n4\n4.1\n25%\n60\n\n\nApplied Soft Computing\n5\n10.5\n27%\n50\n\n\nEngineering Applications of Artificial Intelligence\n5\n7.8\n26%\n40\n\n\n\nSource: Elsevier Journal Finder Results\n\n\n\nPaper 3\n\nPaper title: “Blending Forecasting Models for Commodities Portfolio Optimization” by Rodrigo Hermont Ozon and Robson Guedes\n\n\n\nAbstract:\nThe intricacies of the global commodities market, characterized by its inherent volatility, necessitate robust forecasting methodologies to guide stakeholders in their decision-making processes. Traditional time series forecasting models, while foundational, often grapple with capturing the multifaceted dynamics of commodity prices. This paper introduces an innovative approach to commodities portfolio optimization by synergistically blending time series forecasting models within Pareto Front Scenarios. By integrating bootstrapping techniques across models such as Dynamic Harmonic Regression, DHR with multiple seasonal periods, STL with multiple seasonal, Auto ARIMA, and non-linear regression with cubic splines, we enhance the predictive accuracy and robustness of our forecasting framework. Our findings underscore the efficacy of this integrative approach, offering a nuanced, actionable framework for commodities portfolio optimization. This research not only contributes to the academic discourse on commodities forecasting but also provides practical insights for investors, policymakers, and other stakeholders in the commodities market.\nKeywords: Commodities Portfolio Optimization; Time Series Forecasting; Pareto Front Scenarios\n\n\n\nJournal\nText Match Score (1 to 5)\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nJournal of Commodity Markets\n5\n4.3\n-\n60\n\n\nAgricultural Economics\n5\n4.2\n-\n45\n\n\nFood Policy\n5\n6.8\n-\n30\n\n\nEnergy Economics\n4\n10.8\n-\n30\n\n\nEconomic Modelling\n4\n5.8\n-\n18\n\n\nJournal of Agricultural and Resource Economics\n4\n1.5\n-\n60\n\n\nApplied Economics\n4\n3.0\n-\n50\n\n\nJournal of International Money and Finance\n4\n4.1\n-\n40\n\n\nEmerging Markets Review\n4\n4.1\n-\n30\n\n\nJournal of Futures Markets\n5\n3.2\n-\n40\n\n\n\nSource: Elsevier Journal Finder Results\n\n\n\nPaper 4\n\nPaper title: “Portfolio Optimization with GARCH Models Using Multiple Time Windows for Pareto Frontiers” by Rodrigo Hermont Ozon, Gilberto Reynoso-Meza\n\n\n\nAbstract:\nThis study introduces a novel approach for portfolio optimization by employing Generalized Autoregressive Conditional Heteroskedasticity (GARCH) models to assess risk and construct Pareto frontiers over multiple time windows. Traditional risk measures such as the standard deviation may fail to capture risk accurately in financial markets where volatility is time-varying. By modeling conditional volatility, GARCH models offer a more comprehensive depiction of risk. In this paper, we implement this approach in the non-diversified portfolio optimization of two commodities, corn and soy, projecting their price dynamics 252 days ahead. The results demonstrate that the application of GARCH models and multi-period Pareto frontiers can significantly enhance portfolio optimization, providing fresh insights into purchasing and selling opportunities in the commodities market. This study adds to the current literature by addressing the gaps in applying Pareto frontiers across multiple time windows and utilizing GARCH models for risk measurement.\nKeywords: Portfolio Optimization, GARCH Models, Pareto Frontiers.\n\n\n\nJournal\nText Match Score (1 to 5)\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nJournal of Commodity Markets\n5\n4.3\n-\n60\n\n\nFinance Research Letters\n5\n11.1\n24\n10\n\n\nEnergy Economics\n5\n10.8\n-\n30\n\n\nEconomic Modelling\n5\n5.8\n-\n18\n\n\nJournal of Banking and Finance\n5\n6.4\n25\n40\n\n\nJournal of Behavioral and Experimental Finance\n4\n4.5\n-\n6\n\n\nEmerging Markets Review\n5\n4.1\n-\n30\n\n\nComputers and Electronics in Agriculture\n5\n7.6\n30\n15\n\n\nInternational Economics\n4\n3.9\n-\n45\n\n\nJournal of Financial Markets\n4\n5.2\n-\n50\n\n\n\nSource: Elsevier Journal Finder Results\n\n\n\n\nPaper 5\n\nPaper title: “Impact of the Russia-Ukraine War on Corn Prices, Returns, and Volatility: A Quasi-Experimental Approach” by Rodrigo Hermont Ozon\n\n\n\nAbstract:\nThis paper investigates the impact of the Russia-Ukraine war on corn futures prices, returns, and volatility. Using a quasi-experimental approach with the CausalImpact model, we estimate changes before and after the war’s escalation. The results highlight how geopolitical conflicts affect commodity markets.\nKeywords: Russia-Ukraine War, Corn Prices, Futures, Volatility, CausalImpact Model, Quasi-Experimental Approach.\n\n\n\nJournal\nText Match Score (1 to 5)\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nJournal of Commodity Markets\n5\n4.3\n-\n60\n\n\nAgricultural Economics\n5\n4.2\n-\n45\n\n\nFood Policy\n5\n6.8\n-\n30\n\n\nEnergy Economics\n4\n10.8\n-\n30\n\n\nEconomic Modelling\n4\n5.8\n-\n18\n\n\nJournal of Agricultural and Resource Economics\n4\n1.5\n-\n60\n\n\nApplied Economics\n4\n3.0\n-\n50\n\n\nJournal of International Money and Finance\n4\n4.1\n-\n40\n\n\nEmerging Markets Review\n4\n4.1\n-\n30\n\n\nJournal of Futures Markets\n5\n3.2\n-\n40\n\n\n\nSource: Elsevier Journal Finder Results\n\n\n\nPaper 6\n\nPaper title: “A Commodities Portfolio Optimization Model Recommendation: Blending Time Series Forecasting Models in Pareto Front Scenarios” by Rodrigo Hermont Ozon and Robson Thiago Guedes da Silva\n\n\n\nAbstract:\nThe intricacies of the global commodities market, characterized by its inherent volatility, necessitate robust forecasting methodologies to guide stakeholders in their decision-making processes. Traditional time series forecasting models, while foundational, often grapple with capturing the multifaceted dynamics of commodity prices. This paper introduces an innovative approach to commodities portfolio optimization by synergistically blending time series forecasting models within Pareto Front Scenarios. By integrating bootstrapping techniques across models such as Dynamic Harmonic Regression, DHR with multiple seasonal periods, STL with multiple seasonal, Auto ARIMA, and non-linear regression with cubic splines, we enhance the predictive accuracy and robustness of our forecasting framework. Our findings underscore the efficacy of this integrative approach, offering a nuanced, actionable framework for commodities portfolio optimization. This research not only contributes to the academic discourse on commodities forecasting but also provides practical insights for investors, policymakers, and other stakeholders in the commodities market.\nKeywords: Commodities Portfolio Optimization, Time Series Forecasting, Pareto Front Scenarios.\n\n\n\nJournal\nText Match Score (1 to 5)\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nJournal of Commodity Markets\n5\n4.3\n-\n60\n\n\nFinance Research Letters\n5\n11.1\n24\n10\n\n\nEnergy Economics\n5\n10.8\n-\n30\n\n\nEconomic Modelling\n5\n5.8\n-\n18\n\n\nJournal of Banking and Finance\n5\n6.4\n25\n40\n\n\nJournal of Behavioral and Experimental Finance\n4\n4.5\n-\n6\n\n\nEmerging Markets Review\n5\n4.1\n-\n30\n\n\nComputers and Electronics in Agriculture\n5\n7.6\n30\n15\n\n\nInternational Economics\n4\n3.9\n-\n45\n\n\nJournal of Financial Markets\n4\n5.2\n-\n50\n\n\n\nSource: Elsevier Journal Finder Results\n\n\n\n\nPaper 7\n\nPaper title: “Enhancing Grain Portfolio Risk Management with GAMLSS and MSGARCH” by Rodrigo Hermont Ozon, José Donizzetti de Lima, and Géremi Dranka\n\n\n\nAbstract:\nThis paper presents a novel method integrating Generalized Additive Models for Location, Scale, and Shape (GAMLSS) with Bayesian Markov-Switching GARCH (MSGARCH) models to enhance forecasting in commodity price returns, focusing on grain portfolios. We leverage GAMLSS to model non-normal distributions of return series, crucial for accurately simulating real options. These models then inform the Bayesian MSGARCH framework, improving projections of returns and volatility, essential for effective financial planning and risk management. This innovative approach not only advances practical portfolio management but also contributes to the theoretical development of real options theory. Demonstrating its efficacy, our methodology offers a more informed, strategic approach to the complex world of commodity trading, bridging the gap between theoretical models and practical financial applications.\nKeywords:\nCommodity Portfolio Management, GAMLSS, Monte Carlo Simulation, Bayesian MSGARCH, Real Options Theory, Financial Time Series\n\n\n\nJournal\nText Match Score (1 to 5)\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nJournal of Commodity Markets\n5\n4.3\n-\n60\n\n\nFinance Research Letters\n5\n11.1\n24\n10\n\n\nEnergy Economics\n5\n10.8\n-\n30\n\n\nEconomic Modelling\n5\n5.8\n-\n18\n\n\nJournal of Banking and Finance\n5\n6.4\n25\n40\n\n\nJournal of Behavioral and Experimental Finance\n4\n4.5\n-\n6\n\n\nEmerging Markets Review\n5\n4.1\n-\n30\n\n\nComputers and Electronics in Agriculture\n5\n7.6\n30\n15\n\n\nInternational Economics\n4\n3.9\n-\n45\n\n\nJournal of Financial Markets\n4\n5.2\n-\n50\n\n\n\nSource: Elsevier Journal Finder Results\n\n\n\n\nPaper 8\n\nPaper title: “Improving Risk Management in Grain Portfolios: The Role of GAMLSS and Bayesian MSGARCH Models” by Rodrigo Hermont Ozon and Gilberto Reynoso-Meza\n\n\n\nAbstract:\nThis paper presents a novel method integrating Generalized Additive Models for Location, Scale, and Shape (GAMLSS) with Bayesian Markov-Switching GARCH (MSGARCH) models to enhance forecasting in commodity price returns, focusing on grain portfolios. We leverage GAMLSS to model non-normal distributions of return series, crucial for accurately simulating real options. These models then inform the Bayesian MSGARCH framework, improving projections of returns and volatility, essential for effective financial planning and risk management. This innovative approach not only advances practical portfolio management but also contributes to the theoretical development of real options theory. Demonstrating its efficacy, our methodology offers a more informed, strategic approach to the complex world of commodity trading, bridging the gap between theoretical models and practical financial applications.\nKeywords:\nCommodity Portfolio Management, GAMLSS, Monte Carlo Simulation, Bayesian MSGARCH, Real Options Theory, Financial Time Series\n\n\n\nJournal\nText Match Score (1 to 5)\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nJournal of Commodity Markets\n5\n4.3\n-\n60\n\n\nFinance Research Letters\n5\n11.1\n24\n10\n\n\nEnergy Economics\n5\n10.8\n-\n30\n\n\nEconomic Modelling\n5\n5.8\n-\n18\n\n\nJournal of Banking and Finance\n5\n6.4\n25\n40\n\n\nJournal of Behavioral and Experimental Finance\n4\n4.5\n-\n6\n\n\nEmerging Markets Review\n5\n4.1\n-\n30\n\n\nComputers and Electronics in Agriculture\n5\n7.6\n30\n15\n\n\nInternational Economics\n4\n3.9\n-\n45\n\n\nJournal of Financial Markets\n4\n5.2\n-\n50\n\n\n\nSource: Elsevier Journal Finder Results\n\n\n\n\nPaper 8\n\nPaper title: “Econometric Prices Forecasting Approach and Multiobjective Optimization for Commodity Portfolio Decision-Making” by Rodrigo Hermont Ozon and Gilberto Reynoso-Meza\n\n\n\nAbstract:\nThis paper proposes an innovative approach to agricultural commodity portfolio optimization, leveraging Bayesian GARCH models with Markov Regime Switching shifts to forecast price return series and estimate their conditional volatilities, a departure from the conventional standard deviation. This research is grounded in a meticulous review of diverse methodologies in commodity price forecasting and portfolio optimization, including the recent works of Zhang et al. (2020), who developed a robust framework for forecasting agricultural commodity prices, and Gagnon et al. (2020), who explored the diversification benefits of commodities.\nOur approach utilizes time series data of agricultural commodity prices to construct multi-objective optimization models, identifying optimal Pareto fronts for each quarterly time window. This methodology is informed by the advancements in multi-objective optimization by Chen et al. (2009) and Zitzler et al. (2001), and it is further enriched by the incorporation of reinforcement learning to recommend the most advantageous buy, sell, or hold alternatives. The integration of Bayesian GARCH models with Markov Regime shifts and Reinforcement Learning recommendation models represents a disruptive advancement in the field, offering nuanced insights into the dynamics of commodity prices and refining portfolio theory.\nThis novel convergence of methodologies not only enhances the precision in forecasting commodity price returns and their volatilities but also provides a sophisticated framework for portfolio decision-making, contributing significantly to the ongoing discourse in financial research and the modeling of price time series.\nKeywords:\nBayesian GARCH Models, Markov Regime Shifts, Agricultural Commodity Portfolio, Multi-objective Optimization, Reinforcement Learning Recommendation Models\n\n\n\nJournal\nText Match Score (1 to 5)\nCiteScore\nAcceptance Rate (%)\nTime to First Decision (days)\n\n\n\n\nJournal of Commodity Markets\n5\n4.3\n-\n60\n\n\nFinance Research Letters\n5\n11.1\n24\n10\n\n\nEnergy Economics\n5\n10.8\n-\n30\n\n\nEconomic Modelling\n5\n5.8\n-\n18\n\n\nJournal of Banking and Finance\n5\n6.4\n25\n40\n\n\nJournal of Behavioral and Experimental Finance\n4\n4.5\n-\n6\n\n\nEmerging Markets Review\n5\n4.1\n-\n30\n\n\nComputers and Electronics in Agriculture\n5\n7.6\n30\n15\n\n\nInternational Economics\n4\n3.9\n-\n45\n\n\nJournal of Financial Markets\n4\n5.2\n-\n50\n\n\n\nSource: Elsevier Journal Finder Results",
    "crumbs": [
      "About",
      "Intro",
      "Journals publication plan"
    ]
  },
  {
    "objectID": "time_series_portfolio.html",
    "href": "time_series_portfolio.html",
    "title": "Data Extraction for preselected commodities portfolio",
    "section": "",
    "text": "Abstract\n\n\n\nThis small document have the goal to share the time series extraction and the two basic features building, like price returns and their conditional variance…\n\n\n\n  \n\n\nIntro\n[… to be written …]\n\n\n\nPython codes\n\nPython libsLoading time seriesPrices log-returnsLog-returns conditional variances\n\n\n\n\nCode\n\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nfrom arch import arch_model\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom plotnine import ggplot, aes, geom_line, facet_wrap, labs, theme, element_text, theme_minimal\n\n\n\n\nThe portfolio contains the following commodities price returns:\n\nCorn Futures\nWheat Futures\nKC HRW Wheat Futures\nRough Rice Futures\nFeeder Cattle Futures\nSoyMeal Futures\nSoy Meal Futures\nSoyBeans Futures\n\n\n\nCode\n# Tickers for portfolio\nTICKERS = [\n    \"ZC=F\",  # Corn Futures\n    \"ZO=F\",  # Wheat Futures\n    \"KE=F\",  # KC HRW Wheat Futures\n    \"ZR=F\",  # Rough Rice Futures\n    \"GF=F\",  # Feeder Cattle Futures\n    \"ZS=F\",  # SoyMeal Futures\n    \"ZM=F\",  # Soybean Meal Futures\n    \"ZL=F\"   # SoyBeans Futures\n]\n\n\n# Downloading data from Yahoo Finance\nportfolio_prices = yf.download(TICKERS, start=\"2019-01-01\")['Adj Close']\n\n\n\n[                       0%                       ]\n[************          25%                       ]  2 of 8 completed\n[******************    38%                       ]  3 of 8 completed\n[**********************50%                       ]  4 of 8 completed\n[**********************62%*****                  ]  5 of 8 completed\n[**********************75%***********            ]  6 of 8 completed\n[**********************88%*****************      ]  7 of 8 completed\n[*********************100%***********************]  8 of 8 completed\n\n\nCode\nportfolio_prices.dropna(inplace=True)\n\n# Renaming columns for better readability\nportfolio_prices.columns = [\n    \"corn_fut\",\n    \"wheat_fut\",\n    \"KCWheat_fut\",\n    \"rice_fut\",\n    \"Feeder_Cattle\",\n    \"soymeal_fut\",\n    \"soyF_fut\",\n    \"soybeans_fut\"\n]\n\n\nShowing the prices time series side by side: (data in level)\n\n\nCode\nfrom plotnine import ggplot, aes, geom_line, facet_wrap, labs, theme, element_text, theme_minimal, theme_void\n\n# Preparar os dados no formato long (necessário para plotnine/ggplot2)\nportfolio_prices_long = portfolio_prices.reset_index().melt(id_vars='Date', var_name='Commodity', value_name='Price')\n\ndef plot_with_ggplot(data, title, ylabel, background='white', fig_height=10, fig_width=10):\n    # Cria o gráfico usando plotnine (ggplot)\n    p = (ggplot(data, aes(x='Date', y='Price', color='Commodity')) +\n         geom_line() +\n         facet_wrap('~Commodity', ncol=1, scales='free_y') +  # Um gráfico em cima do outro\n         labs(title=title, x='Date', y=ylabel) +\n         theme_minimal() +  # Define o tema minimalista com fundo branco\n         theme(\n             figure_size=(fig_width, fig_height),  # Ajuste da altura e largura da figura\n             panel_background=element_text(fill=background),\n             plot_background=element_text(fill=background),\n             axis_text_x=element_text(rotation=45, hjust=1),\n             subplots_adjust={'wspace': 0.25, 'hspace': 0.5}  # Ajuste do espaçamento entre os gráficos\n         ))\n    return p\n\np_prices = plot_with_ggplot(portfolio_prices_long, 'Commodity Prices Over Time', 'Price', background='white', fig_height=14, fig_width=8)\n\np_prices\n\n\n&lt;string&gt;:2: FutureWarning: Using repr(plot) to draw and show the plot figure is deprecated and will be removed in a future version. Use plot.show().\nC:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\PYTHON~2\\Lib\\site-packages\\plotnine\\themes\\themeable.py:2419: FutureWarning: You no longer need to use subplots_adjust to make space for the legend or text around the panels. This paramater will be removed in a future version. You can still use 'plot_margin' 'panel_spacing' for your other spacing needs.\n&lt;Figure Size: (800 x 1400)&gt;\n\n\n\n\n\n\n\n\n\n\n\nObtain the returns time series (first feature):\n\\[\n\\mbox{Price log returns}_t = ln(p_t) - ln(p_{t-1})\n\\]\n\n\nCode\n\n# Calculate log returns\nportfolio_log_returns = np.log(portfolio_prices / portfolio_prices.shift(1)).dropna()\nportfolio_log_returns.columns = [\n    \"ret_corn_fut\",\n    \"ret_wheat_fut\",\n    \"ret_KCWheat_fut\",\n    \"ret_rice_fut\",\n    \"ret_Feeder_Cattle\",\n    \"ret_soymeal_fut\",\n    \"ret_soyF_fut\",\n    \"ret_soybeans_fut\"\n]\n\n\nAnd plot it:\n\n\nCode\n# Preparar os dados no formato long para os log-retornos\nportfolio_log_returns_long = portfolio_log_returns.reset_index().melt(id_vars='Date', var_name='Commodity', value_name='Log Return')\n\ndef plot_log_returns_with_ggplot(data, title, ylabel, background='white', fig_height=10, fig_width=10):\n    # Cria o gráfico usando plotnine (ggplot)\n    p = (ggplot(data, aes(x='Date', y='Log Return', color='Commodity')) +\n         geom_line() +\n         facet_wrap('~Commodity', ncol=1, scales='free_y') +  # Um gráfico em cima do outro\n         labs(title=title, x='Date', y=ylabel) +\n         theme_minimal() +  # Define o tema minimalista com fundo branco\n         theme(\n             figure_size=(fig_width, fig_height),  # Ajuste da altura e largura da figura\n             panel_background=element_text(fill=background),\n             plot_background=element_text(fill=background),\n             axis_text_x=element_text(rotation=45, hjust=1),\n             subplots_adjust={'wspace': 0.25, 'hspace': 0.5}  # Ajuste do espaçamento entre os gráficos\n         ))\n    return p\n\np_log_returns = plot_log_returns_with_ggplot(portfolio_log_returns_long, 'Log Returns of Commodities Over Time', 'Log Return', background='white', fig_height=12, fig_width=8)\n\n# Exibir o gráfico\np_log_returns\n\n\n&lt;string&gt;:3: FutureWarning: Using repr(plot) to draw and show the plot figure is deprecated and will be removed in a future version. Use plot.show().\nC:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\PYTHON~2\\Lib\\site-packages\\plotnine\\themes\\themeable.py:2419: FutureWarning: You no longer need to use subplots_adjust to make space for the legend or text around the panels. This paramater will be removed in a future version. You can still use 'plot_margin' 'panel_spacing' for your other spacing needs.\n&lt;Figure Size: (800 x 1200)&gt;\n\n\n\n\n\n\n\n\n\n\n\nAs risk measure, we use the conditional variances (volatilities), to deal better with day by day of the prices log-returns.\nThe GARCH(1,1) model with an asymmetric Student-t distribution is not directly available in most Python libraries. However, we can still use a GARCH(1,1) model with a standard Student-t distribution to estimate the conditional variance. The GARCH(1,1) model is represented as follows:\n\\[\nr_t = \\mu + \\epsilon_t\n\\]\n\\[\n\\epsilon_t = \\sigma_t z_t, \\quad z_t \\sim t_{\\nu}(0, 1)\n\\]\n\\[\n\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n\\]\nWhere:\n\n\\(r_t\\) is the log-return at time \\(t\\).\n\\(\\mu\\) is the mean of the returns.\n\\(\\epsilon_t\\) is the error term, modeled as conditional on past information.\n\\(\\sigma_t^2\\) is the conditional variance at time \\(t\\).\n\\(\\omega, \\alpha, \\beta\\) are the parameters to be estimated, with \\(\\omega &gt; 0, \\alpha \\geq 0, \\beta \\geq 0\\).\n\\(z_t\\) follows a Student-t distribution with \\(\\nu\\) degrees of freedom to capture the heavy tails observed in financial returns.\n\n\n\nCode\n# Initialize an empty DataFrame to store conditional variances\ncond_variances = pd.DataFrame(index=portfolio_log_returns.index, columns=portfolio_log_returns.columns)\n\n# Loop through each commodity's log-returns and fit a GARCH(1,1) model\nfor col in portfolio_log_returns.columns:\n    # Fit a GARCH(1,1) model with a Student-t distribution for each series of log returns\n    model = arch_model(portfolio_log_returns[col], vol='Garch', p=1, q=1, dist='t')\n    res = model.fit(disp='off')\n    \n    # Extract conditional variances and store them in the DataFrame\n    cond_variances[col] = res.conditional_volatility\n\n# Show the first few rows of the conditional variances DataFrame\ncond_variances.head()\n\n\n                           ret_corn_fut  ...  ret_soybeans_fut\nDate                                     ...                  \n2019-01-03 00:00:00+00:00      0.007584  ...          0.007990\n2019-01-04 00:00:00+00:00      9.242537  ...          0.008047\n2019-01-07 00:00:00+00:00      9.472461  ...          0.008299\n2019-01-08 00:00:00+00:00      9.432000  ...          0.008250\n2019-01-09 00:00:00+00:00      9.588762  ...          0.008319\n\n[5 rows x 8 columns]\n\n\nand visualizing them:\n\n\nCode\n# Preparar os dados no formato long para as variâncias condicionais\ncond_variances_long = cond_variances.reset_index().melt(id_vars='Date', var_name='Commodity', value_name='Conditional Variance')\n\n# Função para criar o gráfico com fundo branco ou transparente e ajustar o tamanho da figura\ndef plot_cond_variances_with_ggplot(data, title, ylabel, background='white', fig_height=10, fig_width=10):\n    # Cria o gráfico usando plotnine (ggplot)\n    p = (ggplot(data, aes(x='Date', y='Conditional Variance', color='Commodity')) +\n         geom_line() +\n         facet_wrap('~Commodity', ncol=1, scales='free_y') +  # Um gráfico em cima do outro\n         labs(title=title, x='Date', y=ylabel) +\n         theme_minimal() +  # Define o tema minimalista com fundo branco\n         theme(\n             figure_size=(fig_width, fig_height),  # Ajuste da altura e largura da figura\n             panel_background=element_text(fill=background),\n             plot_background=element_text(fill=background),\n             axis_text_x=element_text(rotation=45, hjust=1),\n             subplots_adjust={'wspace': 0.25, 'hspace': 0.5}  # Ajuste do espaçamento entre os gráficos\n         ))\n    return p\n\n# Exemplo de uso para as variâncias condicionais das commodities\np_cond_variances = plot_cond_variances_with_ggplot(cond_variances_long, 'Conditional Variances Over Time (GARCH(1,1))', 'Conditional Variance', background='white', fig_height=12, fig_width=8)\n\np_cond_variances\n\n\n&lt;string&gt;:2: FutureWarning: Using repr(plot) to draw and show the plot figure is deprecated and will be removed in a future version. Use plot.show().\nC:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\PYTHON~2\\Lib\\site-packages\\plotnine\\themes\\themeable.py:2419: FutureWarning: You no longer need to use subplots_adjust to make space for the legend or text around the panels. This paramater will be removed in a future version. You can still use 'plot_margin' 'panel_spacing' for your other spacing needs.\n&lt;Figure Size: (800 x 1200)&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR codes\n\nR packagesPortfolio set\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\n#library(plotly)\nlibrary(rugarch)\nlibrary(timeSeries)\nlibrary(fPortfolio)\nlibrary(quantmod)\nlibrary(caTools)\nlibrary(PerformanceAnalytics)\nlibrary(MASS)\nlibrary(PortfolioAnalytics)\nlibrary(ROI)\nrequire(ROI.plugin.glpk)\nrequire(ROI.plugin.quadprog)\nlibrary(quadprog)\nlibrary(corpcor)\nlibrary(DEoptim)\nlibrary(cowplot) # devtools::install_github(\"wilkelab/cowplot/\")\nlibrary(lattice)\nlibrary(timetk)\n\n\n\n\nLoading time series data, for portfolio setting…\n\n\nCode\ntickers &lt;- c(\n         \"ZC=F\", # Corn Futures\n         \"ZO=F\", # Wheat Futures\n         \"KE=F\", # Futuros KC HRW Wheat Futures\n         \"ZR=F\", # Rough Rice Futures\n         \"GF=F\", # Feeder Cattle Futures\n         \"ZS=F\", # SoyMeal Futures \n         \"ZM=F\", # Futuros farelo soja\n         \"ZL=F\"  # SoyBeans Futures\n)\n\n\nObtain daily prices and their returns:\n\n\nCode\nportfolioPrices &lt;- NULL\n  for ( Ticker in tickers )\n    portfolioPrices &lt;- cbind(\n      portfolioPrices, \n      getSymbols.yahoo(\n        Ticker,\n        from = \"2019-01-01\",\n        auto.assign = FALSE\n      )[,4]\n    )\n\nportfolioPrices &lt;- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]\n\ncolnames(portfolioPrices) &lt;- c(\n  \"corn_fut\",\n  \"wheat_fut\",\n  \"KCWheat_fut\",\n  \"rice_fut\",\n  \"Feeder_Cattle\",\n  \"soymeal_fut\",\n  \"soyF_fut\",\n  \"soybeans_fut\"\n)\n\ntail(portfolioPrices)\n\n\n           corn_fut wheat_fut KCWheat_fut rice_fut Feeder_Cattle soymeal_fut\n2025-01-29   497.00    350.00      580.25   1413.0       280.550     1060.50\n2025-01-30   490.25    349.25      588.25   1393.5       281.900     1044.00\n2025-01-31   482.00    347.50      579.25   1384.5       275.725     1042.00\n2025-02-03   488.75    353.00      585.75   1373.0       270.500     1058.25\n2025-02-04   494.50    359.25      594.75   1355.0       268.250     1075.00\n2025-02-05   493.25    367.75      591.75   1350.0       270.725     1057.00\n           soyF_fut soybeans_fut\n2025-01-29    309.8        44.97\n2025-01-30    304.7        44.98\n2025-01-31    301.1        46.11\n2025-02-03    303.7        46.51\n2025-02-04    314.0        45.76\n2025-02-05    308.3        45.09\n\n\nPlotting the time series prices (in level):\n\n\nCode\nportfolioPrices |&gt; as.data.frame() |&gt;\n  mutate(\n    time = seq_along( corn_fut )\n  ) |&gt;\n  pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n      ) |&gt;\n  group_by(Variables) |&gt;\n  plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  theme(\n    strip.background = element_rect(fill = \"white\", colour = \"white\")\n  )\n\n\n\n\n\n\n\n\n\nObtain the returns time series (first feature):\n\\[\n\\mbox{Price log returns}_t = ln(p_t) - ln(p_{t-1})\n\\]\n\n\nCode\n# Calculate log returns for the portfolio prices\nportfolioReturs &lt;- na.omit(diff(log(portfolioPrices))) |&gt; as.data.frame()\n\ncolnames(portfolioReturs) &lt;- c(\n  \"ret_corn_fut\",\n  \"ret_wheat_fut\",\n  \"ret_KCWheat_fut\",\n  \"ret_rice_fut\",\n  \"ret_Feeder_Cattle\",\n  \"ret_soymeal_fut\",\n  \"ret_soyF_fut\",\n  \"ret_soybeans_fut\"\n)\n\nglimpse(portfolioReturs)\n\n\nRows: 1,533\nColumns: 8\n$ ret_corn_fut      &lt;dbl&gt; 0.0105891128, 0.0085218477, -0.0019601444, -0.005903…\n$ ret_wheat_fut     &lt;dbl&gt; 0.0008980692, 0.0053715438, -0.0017873106, 0.0115608…\n$ ret_KCWheat_fut   &lt;dbl&gt; 0.0220892515, 0.0049529571, -0.0059464992, 0.0039682…\n$ ret_rice_fut      &lt;dbl&gt; 0.0083930387, 0.0053934919, 0.0174507579, 0.00813596…\n$ ret_Feeder_Cattle &lt;dbl&gt; -0.0096783375, -0.0111522135, 0.0075628145, 0.011068…\n$ ret_soymeal_fut   &lt;dbl&gt; 0.0061281529, 0.0102224954, 0.0030190774, -0.0065988…\n$ ret_soyF_fut      &lt;dbl&gt; 0.0054513913, 0.0076457646, 0.0097900861, -0.0018874…\n$ ret_soybeans_fut  &lt;dbl&gt; 0.0099858421, 0.0081286732, -0.0052938051, -0.002834…\n\n\nCode\n#portfolioReturs &lt;- as.timeSeries(portfolioReturs)\n\n\nPlot all time series and their returns:\n\n\nCode\nportfolioReturs |&gt; \n  mutate(\n    time = seq_along( ret_corn_fut )\n  ) |&gt;\n  pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n      ) |&gt;\n  group_by(Variables) |&gt;\n  plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  theme(\n    strip.background = element_rect(fill = \"white\", colour = \"white\")\n  )\n\n\n\n\n\n\n\n\n\nPlotting the histograms:\n\n\nCode\nportfolioPrices_df &lt;- as_tibble(portfolioPrices, rownames = \"date\")\nportfolioPrices_df$date &lt;- ymd(portfolioPrices_df$date)\n\nportfolioReturs_df &lt;- na.omit( ROC( portfolioPrices ), type = \"discrete\" ) |&gt;\n  as_tibble(rownames = \"date\")\nportfolioReturs_df$date &lt;- ymd(portfolioReturs_df$date)\ncolnames(portfolioReturs_df) &lt;- c(\n  \"date\",\n  \"ret_corn_fut\",\n  \"ret_wheat_fut\",\n  \"ret_KCWheat_fut\",\n  \"ret_rice_fut\",\n  \"ret_Feeder_Cattle\",\n  \"ret_soymeal_fut\",\n  \"ret_soyF_fut\",\n  \"ret_soybeans_fut\"\n)\n\n# Remover a coluna com nome NA\nportfolioReturs_df &lt;- portfolioReturs_df[, !is.na(colnames(portfolioReturs_df))]\n\n# Verificar novamente os nomes das colunas para garantir que estão corretos\ncolnames(portfolioReturs_df)\n\n\n[1] \"date\"              \"ret_corn_fut\"      \"ret_wheat_fut\"    \n[4] \"ret_KCWheat_fut\"   \"ret_rice_fut\"      \"ret_Feeder_Cattle\"\n[7] \"ret_soymeal_fut\"   \"ret_soyF_fut\"      \"ret_soybeans_fut\" \n\n\nCode\nportfolioReturs_long &lt;- portfolioReturs_df |&gt; \n  pivot_longer(\n    cols = -date, # Exclui a coluna de data\n    names_to = \"fut_type\", \n    values_to = \"returns\"\n  )\n\nggplot(portfolioReturs_long, aes(x = returns)) + \n  geom_histogram(aes(y = ..density..), binwidth = .01, color = \"black\", fill = \"white\") +\n  geom_density(alpha = .2, fill=\"lightgray\") +\n  theme_minimal() +\n  theme(\n    axis.line  = element_line(colour = \"black\"),\n    axis.text  = element_text(colour = \"black\"),  \n    axis.ticks = element_line(colour = \"black\"), \n    legend.position = c(.1,.9), \n    panel.grid.major = element_blank(), \n    panel.grid.minor = element_blank()\n  ) +\n  theme(plot.title   = element_text(size = 10),  \n        axis.title.x = element_text(size = 7), \n        axis.title.y = element_text(size = 7)) + \n  labs(x = \"Returns\", y = \"Density\") +\n  facet_wrap(~fut_type, scales = \"free\", ncol = 2) \n\n\n\n\n\n\n\n\n\nAnd finnaly, the last feature, is called, the conditional variance (risk measure), obtained by GARCH(1,1) model, formalized as:\nThe GARCH(1,1) model with asymmetric Student-t distribution can be represented mathematically as:\n\\[\nr_t = \\mu + \\epsilon_t\n\\]\n\\[\n\\epsilon_t = \\sigma_t z_t, \\quad z_t \\sim t_{\\nu}(0, 1)\n\\]\n\\[\n\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n\\]\nWhere:\n\n\\(r_t\\) is the return at time \\(t\\).\n\\(\\mu\\) is the mean of the returns.\n\\(\\epsilon_t\\) is the error term, modeled as conditional on past information.\n\\(\\sigma_t^2\\) is the conditional variance at time \\(t\\).\n\\(\\omega, \\alpha, \\beta\\) are the parameters to be estimated, with \\(\\omega &gt; 0, \\alpha \\geq 0, \\beta \\geq 0\\).\n\\(z_t\\) follows an asymmetric Student-t distribution with \\(\\nu\\) degrees of freedom to better capture the heavy tails and skewness observed in financial returns.\n\n\n\nCode\n# Load necessary packages\nlibrary(rugarch)\n\n# Define the GARCH(1,1) model specification with Student-t distribution\nspec &lt;- ugarchspec(\n  variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1)),\n  mean.model = list(armaOrder = c(0, 0), include.mean = TRUE),\n  distribution.model = \"std\" # Using Student-t distribution\n)\n\n# Estimate the model for each asset in the portfolio and extract conditional variances\ngarch_models &lt;- list()\nconditional_variances &lt;- list()\n\nfor (i in colnames(portfolioReturs)) {\n  garch_models[[i]] &lt;- ugarchfit(spec, data = portfolioReturs[[i]])\n  conditional_variances[[i]] &lt;- sigma(garch_models[[i]])^2\n}\n\n# Convert conditional variances list to a data frame\nconditional_variances_df &lt;- do.call(cbind, conditional_variances) %&gt;%\n  as.data.frame() %&gt;%\n  mutate(time = seq_along(conditional_variances[[1]]))\n\ncolnames(conditional_variances_df) &lt;- c(\n  \"cond_var_corn_fut\",\n  \"cond_var_wheat_fut\",\n  \"cond_var_KCWheat_fut\",\n  \"cond_var_rice_fut\",\n  \"cond_var_Feeder_Cattle\",\n  \"cond_var_soymeal_fut\",\n  \"cond_var_soyF_fut\",\n  \"cond_var_soybeans_fut\",\n  \"time\"\n)\n\n# Reshape data for plotting\nconditional_variances_long &lt;- conditional_variances_df %&gt;%\n  pivot_longer(!time, names_to = \"Variables\", values_to = \"Value\")\n\n\nAnd the plot of the conditional variance (risk):\n\n\nCode\nconditional_variances_long |&gt; \n  group_by(Variables) |&gt;\n  plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  theme(\n    strip.background = element_rect(fill = \"white\", colour = \"white\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n\n\n\nReferences\nGujarati, D., N. (2004) Basic Econometrics, fourth edition, The McGraw−Hill Companies\nHair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2019). Multivariate Data Analysis. Pearson.\nHyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on oct 2023.\n \n \n\n\n\nCode\n# Total timing to compile this Quarto document\n\nend_time = datetime.now()\ntime_diff = end_time - start_time\n\nprint(f\"Total Quarto document compiling time: {time_diff}\")\n\n\nTotal Quarto document compiling time: 0:00:18.944925",
    "crumbs": [
      "About",
      "Predictive Models",
      "Data Extraction for preselected commodities portfolio"
    ]
  },
  {
    "objectID": "projects.html#project-1",
    "href": "projects.html#project-1",
    "title": "Projects",
    "section": "Project 1",
    "text": "Project 1\n\nOur first Colab Notebook  here\n\n This project is related with the step News and Impact on price and volatilities dynamics"
  },
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2\n This project aims to find how and why the corn prices flows down for the zero in 2024-jun-16.\n\nMERCADO GLOBAL DE ARROZ ENFRENTA FORTE VOLATILIDADE EM JUNHO DE 2024\nPreço do Arroz Marca Zero no Gráfico em 16 de Junho: Erro Técnico ou Anomalia no Mercado?\nO Yahoo Finance, uma plataforma amplamente utilizada para acessar dados financeiros, cotações em tempo real e gráficos históricos, apresentou um dado intrigante sobre as variações do preço do arroz. No dia 16 de junho de 2024, o preço do alimento foi registrado como zero. Essa informação incomum levanta questionamentos sobre sua origem, com duas possíveis explicações: um erro técnico na plataforma ou uma anomalia no mercado de commodities.\nErro Técnico\nEspecialistas sugerem que a hipótese de um erro técnico não deve ser descartada. Falhas em plataformas financeiras podem ocorrer por problemas no endpoint, parâmetros incorretos ou dificuldades relacionadas ao processamento de dados por meio de APIs. Vale destacar que a data em questão cai em um domingo, dia em que muitos mercados permanecem fechados, o que pode ter gerado inconsistências nos registros.\nAnomalia no Mercado de Commodities\nPor outro lado, o mercado de commodities agrícolas, como o arroz, vive constante volatilidade devido a fatores como mudanças climáticas, safras impactadas, variações na demanda global e problemas logísticos. Em junho de 2024, os preços globais do arroz apresentaram um leve aumento de 0,5%, mas começaram a cair na metade do mês. Esse movimento foi impulsionado pela redução na demanda internacional e pelo aumento na oferta de exportação.\nAlém disso, previsões otimistas de produção nos principais países asiáticos indicaram um aumento global de 2% em relação ao ano anterior, contribuindo para a queda dos preços. No Brasil, o avanço no plantio da nova safra e a realização de leilões governamentais com valores abaixo dos registrados anteriormente pressionaram as cotações.\nA tendência de baixa continuou nos meses seguintes, com os preços internacionais atingindo, em novembro, o menor patamar em seis meses. A combinação de uma oferta crescente e um cenário positivo de produção nos principais produtores asiáticos intensificou a queda no mercado global.\nConclusão\nEmbora o registro de preço zero no dia 16 de junho tenha causado estranheza, a hipótese mais plausível é a ocorrência de um erro técnico na plataforma, devido à falta de movimentação no mercado nesse dia. Ainda assim, a volatilidade observada no mercado global de arroz durante o período reflete tendências de oferta e demanda, com a expectativa de safras robustas influenciando significativamente a queda nos preços. É essencial que plataformas financeiras revisem suas metodologias de coleta de dados para evitar informações equivocadas que possam confundir investidores e analistas.\nAppendix\nGráfico feito pela plataforma Yahoo finance\n\nREFERÊNCIAS\nastera.com\ninfoarroz.org\ngloborural.globo.com\nYahoo!Finance\nPor: Gabrielly dos Santos Mateus da Rosa, Rodrigo Hermont Ozon e Ricardo Vianna."
  },
  {
    "objectID": "projects.html#project-3",
    "href": "projects.html#project-3",
    "title": "Projects",
    "section": "Project 3",
    "text": "Project 3"
  },
  {
    "objectID": "news.html#analyzing-the-causal-impact-of-news-on-commodity-prices-returns-and-volatility",
    "href": "news.html#analyzing-the-causal-impact-of-news-on-commodity-prices-returns-and-volatility",
    "title": "News and Impact on price and volatilities dynamics",
    "section": "Analyzing the Causal Impact of News on Commodity Prices, Returns, and Volatility",
    "text": "Analyzing the Causal Impact of News on Commodity Prices, Returns, and Volatility\nThe hypothesis that abrupt changes in prices, returns, and volatility in agricultural commodity markets are driven by emerging market news is supported by a robust body of literature. One of the foundational works in this area is Robert Engle’s introduction of the News Impact Curve (Engle, 1993), which demonstrates how news can asymmetrically affect volatility in financial markets. Engle’s work shows that negative news tends to increase volatility more than positive news, creating a nonlinear relationship between news and market behavior. This framework suggests that sudden shifts in market conditions may be attributed to external news shocks that alter expectations and investor sentiment, thereby influencing price dynamics and return volatility.\nIn the context of agricultural commodities, this phenomenon is even more pronounced due to the sensitivity of these markets to exogenous shocks such as geopolitical developments, climatic events, and policy changes. A similar argument was made in the work of Ozon (2008), who applied volatility forecasting models to the Brazilian agricultural market. His research, which utilized data-driven models for volatility prediction, highlights the importance of incorporating external information, such as market news, into predictive models to capture the impact of unforeseen market shifts. Ozon’s findings suggest that neglecting the influence of market news can lead to significant forecasting errors, particularly in markets characterized by high volatility and abrupt price changes. His work is documented in the project repository at this link.\n\nObjective of Causal Analysis Using Market News and Search Trends\nBuilding on the insights provided by Engle and Ozon, this research aims to investigate the causal relationship between news events, search trends, and market volatility in agricultural commodity markets. Our hypothesis is that news events, particularly those that are not easily quantifiable through traditional numerical data, have a measurable and statistically significant effect on commodity prices and returns. Additionally, we will explore how search trends (e.g., Google Trends data) for specific keywords related to commodities reflect real-time market sentiment and drive price changes.\nThis study will utilize causal inference techniques to test whether certain news events are not only correlated with but are causally linked to market volatility. The innovative contribution of this research lies in combining news data with large language models (LLMs), such as GPT, to automatically identify and rank the most impactful news events. These LLMs will help in filtering vast amounts of information, pinpointing the events most likely to influence market movements.\n\n\nMethodological Approach\n\nData Collection: We will collect time-series data on commodity prices, returns, and volatility from various financial databases. Additionally, news articles and reports related to agricultural commodities will be gathered from reputable financial news sources.\nGoogle Trends: We will use Google Trends data to track search frequencies for specific keywords related to the commodities under study. The hypothesis here is that increased search activity correlates with heightened market volatility, as more people become aware of emerging news events.\nNews Filtering Using LLMs: LLMs, such as GPT, will be employed to filter news articles and highlight those with the highest potential to influence market dynamics. This automated news filtering process allows us to focus on key events that are likely to cause market disruptions.\nCausal Impact Testing: Once we have identified key news events, we will conduct causal impact tests using methodologies such as Granger causality tests, Bayesian structural time series (BSTS) or maybe the most recent CausalImpact algorithm (Brodersen et. al., 2015), models. These tests will allow us to determine whether a specific news event had a statistically significant impact on commodity prices or volatility.\nEvaluation: Finally, we will evaluate the overall effectiveness of our news-based predictive models by comparing them against baseline models that do not account for news events or search trends.\n\n\n\nExpected Contributions\nThe innovative contribution of this research is twofold. First, it introduces a novel framework that links market sentiment, captured through news data and search trends, to real-time volatility and price forecasting. Second, by incorporating LLMs for news filtering, the research provides a more scalable and efficient method of analyzing vast amounts of textual data, which is crucial in fast-moving markets.\nThis research aims to provide both theoretical insights and practical tools for market participants, enabling them to anticipate market shifts based on news events and search trends, and adjust their portfolio strategies accordingly.\n \n \n\n\n\nReferences\n\nBrodersen, K. H., Gallusser, F., Koehler, J., Remy, N., & Scott, S. L. (2015). Inferring causal impact using Bayesian structural time-series models. Annals of Applied Statistics, 9, 247–274.\nEngle, R. F. (1993). Statistical Models for Financial Volatility. Financial Analysts Journal.\nOzon, R. H. (2008). Volatility Forecasting in Agricultural Markets. Available at this link.",
    "crumbs": [
      "About",
      "Commodities (grains) news"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the PIBIC and PIBITI Jr.",
    "section": "",
    "text": "About the PIBIC and PIBITI Jr.\nThis project is carried out as part of a research initiation (PIBIC and PIBITI Jr.) at PUCPR, focusing on advanced forecasting and optimization techniques applied to agriculture.\n\nRodrigoRicardoGabrielly\n\n\n  \n\nAdvisor/Researcher\n\nEconomist and Msc. in Economic Development (UFPR, 2008 & 2010), PhD Candidate at PPGEPS/PUCPR (2022-2026)\n\n\n\n\n\n\n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n\n    \n    \n        \n    \n    \n    \n    \n        \n    \n\n\n  \n\n\n\n  \n\nComputer Science Researcher at PUCPR\n\nUndergratuate student \\(\\Rightarrow\\) Computer Science Website at PUCPR\n\n\n\n\n\n\n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n    \n    \n        \n    \n\n\n  \n\n\n  \n\nAdventist College student\n\nLink for the College institution \\(\\Rightarrow\\) Colégio Adventista Pinhais"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "AgriPredict",
    "section": "",
    "text": "This research project is being conducted at PUCPR with the support of undergraduate students participating in the Scientific Initiation Program (PIBIC Jr.). The primary aim is to explore advanced predictive models and multi-objective optimization approaches applied to agricultural commodities, particularly focusing on grains.\nThe research combines the efforts of faculty members and students, promoting an enriching learning experience while addressing real-world agricultural challenges. By leveraging time series models for price forecasting and optimization techniques, this project aims to provide insights that support decision-making processes in the agricultural sector.\nThrough the collaboration with our undergraduate students, we focus on developing practical skills and research capabilities, empowering the next generation of researchers and professionals in agricultural analytics and data-driven decision-making.",
    "crumbs": [
      "About",
      "Intro"
    ]
  },
  {
    "objectID": "introduction.html#learn-more",
    "href": "introduction.html#learn-more",
    "title": "AgriPredict",
    "section": "Learn More",
    "text": "Learn More\nFor more information about the Scientific Initiation Program, visit the PUCPR Scientific Initiation Program.",
    "crumbs": [
      "About",
      "Intro"
    ]
  },
  {
    "objectID": "predictive_model.html#data-collection-and-preprocessing",
    "href": "predictive_model.html#data-collection-and-preprocessing",
    "title": "Final Project: Time Series Forecasting with LSTMs, Neural Networks Eng. Class",
    "section": "Data Collection and Preprocessing",
    "text": "Data Collection and Preprocessing\nPython libs\n\n\nCode\n# Importing necessary libraries\nimport pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import ParameterGrid\nimport psutil\nimport time\nimport json\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Additional libraries for residual analysis\nfrom statsmodels.stats.diagnostic import acorr_ljungbox, het_breuschpagan\nimport statsmodels.api as sm\n\n\nFirst of all, we need to check the hardware availability:\n\n\nCode\n# Collecting hardware information\ndef get_system_info():\n    system_info = {\n        'CPU_cores': psutil.cpu_count(logical=True),\n        'CPU_freq_MHz': psutil.cpu_freq().current,\n        'Total_RAM_GB': round(psutil.virtual_memory().total / (1024 ** 3), 2),\n        'Available_RAM_GB': round(psutil.virtual_memory().available / (1024 ** 3), 2),\n        'GPU_info': 'Not available'  # Placeholder, can be expanded with libraries like GPUtil\n    }\n    return system_info\n\nsystem_info = get_system_info()\nprint(\"System Information:\", system_info)\n\n\nSystem Information: {'CPU_cores': 12, 'CPU_freq_MHz': 1800.0, 'Total_RAM_GB': 31.69, 'Available_RAM_GB': 15.53, 'GPU_info': 'Not available'}\n\n\nLoading data:\n\n\nCode\n# Defining the tickers\ntickers = [\n    \"ZC=F\",  # Corn Futures\n    \"ZW=F\",  # Wheat Futures\n    \"KE=F\",  # KC HRW Wheat Futures\n    \"ZR=F\",  # Rough Rice Futures\n    \"GF=F\",  # Feeder Cattle Futures\n    \"ZM=F\",  # Soybean Meal Futures\n    \"ZL=F\",  # Soybean Oil Futures\n    \"ZS=F\"   # Soybean Futures\n]\n\n# Downloading price data\nprint(\"\\nDownloading price data...\")\ndata = yf.download(tickers, start=\"2015-01-01\")['Close']\n\n# Handling missing data\nprint(\"\\nHandling missing data...\")\ndata.fillna(method='ffill', inplace=True)  # Forward fill\ndata.dropna(axis=1, how='all', inplace=True)  # Drop columns with all NaNs\ndata.dropna(axis=0, how='any', inplace=True)  # Drop rows with any NaNs\n\n# Verify data\nprint(\"\\nData columns and their non-null counts:\")\nprint(data.count())\n\nif data.empty:\n    print(\"Data is empty after cleaning. Exiting.\")\n    exit()\n\n# Calculating logarithmic returns\nreturns = np.log(data / data.shift(1)).dropna()\n\n# Verify returns\nprint(\"\\nReturns DataFrame info:\")\nprint(returns.info())\nprint(returns.head())\n\nif returns.empty:\n    print(\"Returns DataFrame is empty. Exiting.\")\n    exit()\n    \n\nreturns.head() # Showing time series used (without features)\n\n\n\nDownloading price data...\n\n\n[                       0%                       ][************          25%                       ]  2 of 8 completed[************          25%                       ]  2 of 8 completed[**********************50%                       ]  4 of 8 completed[**********************62%*****                  ]  5 of 8 completed[**********************75%***********            ]  6 of 8 completed[**********************88%*****************      ]  7 of 8 completed[*********************100%***********************]  8 of 8 completed\n\n\n\nHandling missing data...\n\nData columns and their non-null counts:\nTicker\nGF=F    2539\nKE=F    2539\nZC=F    2539\nZL=F    2539\nZM=F    2539\nZR=F    2539\nZS=F    2539\nZW=F    2539\ndtype: int64\n\nReturns DataFrame info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 2538 entries, 2015-01-05 00:00:00+00:00 to 2025-02-06 00:00:00+00:00\nData columns (total 8 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   GF=F    2538 non-null   float64\n 1   KE=F    2538 non-null   float64\n 2   ZC=F    2538 non-null   float64\n 3   ZL=F    2538 non-null   float64\n 4   ZM=F    2538 non-null   float64\n 5   ZR=F    2538 non-null   float64\n 6   ZS=F    2538 non-null   float64\n 7   ZW=F    2538 non-null   float64\ndtypes: float64(8)\nmemory usage: 178.5 KB\nNone\nTicker                         GF=F      KE=F      ZC=F      ZL=F      ZM=F  \\\nDate                                                                          \n2015-01-05 00:00:00+00:00  0.007673  0.012483  0.025570  0.023203  0.034462   \n2015-01-06 00:00:00+00:00 -0.004330  0.010350 -0.002466 -0.000306  0.004866   \n2015-01-07 00:00:00+00:00  0.004219 -0.017983 -0.021842  0.008832 -0.006222   \n2015-01-08 00:00:00+00:00 -0.000111 -0.019956 -0.005060  0.018029 -0.019732   \n2015-01-09 00:00:00+00:00 -0.014284 -0.012001  0.015104 -0.001192  0.006896   \n\nTicker                         ZR=F      ZS=F      ZW=F  \nDate                                                     \n2015-01-05 00:00:00+00:00  0.003537  0.036483  0.013245  \n2015-01-06 00:00:00+00:00  0.002644  0.010762  0.004658  \n2015-01-07 00:00:00+00:00  0.004392  0.001664 -0.020919  \n2015-01-08 00:00:00+00:00 -0.010130 -0.007389 -0.021806  \n2015-01-09 00:00:00+00:00  0.002653  0.006201 -0.005748  \n\n\n\n\n\n\n\n\n\n\n\nTicker\nGF=F\nKE=F\nZC=F\nZL=F\nZM=F\nZR=F\nZS=F\nZW=F\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n2015-01-05 00:00:00+00:00\n0.007673\n0.012483\n0.025570\n0.023203\n0.034462\n0.003537\n0.036483\n0.013245\n\n\n2015-01-06 00:00:00+00:00\n-0.004330\n0.010350\n-0.002466\n-0.000306\n0.004866\n0.002644\n0.010762\n0.004658\n\n\n2015-01-07 00:00:00+00:00\n0.004219\n-0.017983\n-0.021842\n0.008832\n-0.006222\n0.004392\n0.001664\n-0.020919\n\n\n2015-01-08 00:00:00+00:00\n-0.000111\n-0.019956\n-0.005060\n0.018029\n-0.019732\n-0.010130\n-0.007389\n-0.021806\n\n\n2015-01-09 00:00:00+00:00\n-0.014284\n-0.012001\n0.015104\n-0.001192\n0.006896\n0.002653\n0.006201\n-0.005748\n\n\n\n\n\n\n\nPlotting the time series of prices and returns side by side (2 per row)\n\n\nCode\n# Create a directory for plots if it doesn't exist\nplots_dir = 'plots'\nif not os.path.exists(plots_dir):\n    os.makedirs(plots_dir)\n\n# Plot prices\nprint(\"\\nPlotting time series of prices...\")\nnum_cols = 2  # Number of plots per row\nnum_plots = len(data.columns)\nnum_rows = (num_plots + num_cols - 1) // num_cols  # Ensure enough rows\n\nfig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\naxs = axs.flatten()\n\nfor i, col in enumerate(data.columns):\n    axs[i].plot(data.index, data[col])\n    axs[i].set_title(f'Price Series - {col}')\n    axs[i].set_xlabel('Date')\n    axs[i].set_ylabel('Price')\n\n# Hide unused subplots\nfor j in range(i + 1, len(axs)):\n    fig.delaxes(axs[j])\n\nplt.tight_layout()\nplt.savefig(os.path.join(plots_dir, 'price_series.png'))\nplt.show()\nplt.close()\n\n# Plot returns\nprint(\"Plotting time series of returns...\")\nnum_plots_ret = len(returns.columns)\nnum_rows_ret = (num_plots_ret + num_cols - 1) // num_cols\n\nfig, axs = plt.subplots(num_rows_ret, num_cols, figsize=(15, 5 * num_rows_ret))\naxs = axs.flatten()\n\nfor i, col in enumerate(returns.columns):\n    axs[i].plot(returns.index, returns[col])\n    axs[i].set_title(f'Return Series - {col}')\n    axs[i].set_xlabel('Date')\n    axs[i].set_ylabel('Log Return')\n\n# Hide unused subplots\nfor j in range(i + 1, len(axs)):\n    fig.delaxes(axs[j])\n\nplt.tight_layout()\nplt.savefig(os.path.join(plots_dir, 'return_series.png'))\nplt.show()\nplt.close()\n\n\n\nPlotting time series of prices...\n\n\n\n\n\n\n\n\n\nPlotting time series of returns...\n\n\n\n\n\n\n\n\n\nPreprocessing data for LSTM time series modelling:\n\n\nCode\n# Function to prepare data for LSTM\ndef prepare_data(series, time_steps):\n    X, y = [], []\n    for i in range(len(series) - time_steps):\n        X.append(series[i:(i + time_steps)])\n        y.append(series[i + time_steps])\n    return np.array(X), np.array(y)\n\n\nSetting the parameters:\n\n\nCode\n# Defining parameters\ntime_steps = 5  # Number of time steps\nepochs = 10  # Reduced epochs for faster execution during testing\n\n# Dictionaries to store results\nmodels = {}\nhistories = {}\nmse_results = {}\nscalers = {}\npredictions = {}\nbest_params_dict = {}\nresiduals_analysis = {}\n\n# Directory to save reports and graphs\nreport_dir = 'report'\nif not os.path.exists(report_dir):\n    os.makedirs(report_dir)",
    "crumbs": [
      "About",
      "Predictive Models"
    ]
  },
  {
    "objectID": "predictive_model.html#lstm-time-series-model-fitting",
    "href": "predictive_model.html#lstm-time-series-model-fitting",
    "title": "Final Project: Time Series Forecasting with LSTMs, Neural Networks Eng. Class",
    "section": "LSTM time series model fitting",
    "text": "LSTM time series model fitting\n\n\nCode\n# Loop through each time series\nfor col in returns.columns:\n    print(f\"\\nProcessing column: {col}\")\n    series = returns[col].values.reshape(-1, 1)\n    \n    # Check if series is empty\n    if len(series) == 0:\n        print(f\"Series {col} is empty after preprocessing. Skipping.\")\n        continue\n    \n    print(f\"Series {col} has {len(series)} data points.\")\n    \n    # Normalizing data\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    series_scaled = scaler.fit_transform(series)\n    scalers[col] = scaler  # Storing the scaler for later inversion\n    \n    # Preparing data\n    X, y = prepare_data(series_scaled, time_steps)\n    \n    # Check if X and y are non-empty\n    if X.shape[0] == 0:\n        print(f\"Not enough data points in {col} after preparation. Skipping.\")\n        continue\n    \n    # Splitting into training and test sets\n    split_index = int(0.8 * len(X))\n    X_train_full, X_test = X[:split_index], X[split_index:]\n    y_train_full, y_test = y[:split_index], y[split_index:]\n    X_train_full = X_train_full.reshape((X_train_full.shape[0], X_train_full.shape[1], 1))\n    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n    \n    # Hyperparameter grid for Grid Search\n    param_grid = {\n        'neurons': [30, 50],\n        'learning_rate': [0.001, 0.01],\n        'activation': ['tanh', 'relu'],\n        'batch_size': [32, 64]\n    }\n    grid = ParameterGrid(param_grid)\n    \n    # Initializing variables to store best results\n    best_mse = float('inf')\n    best_params = None\n    best_model = None\n    \n    # Performing Grid Search\n    print(f\"Performing Grid Search for {col}...\")\n    for params in grid:\n        model = Sequential()\n        model.add(LSTM(params['neurons'], activation=params['activation'], input_shape=(time_steps, 1)))\n        model.add(Dense(1))\n        optimizer = Adam(learning_rate=params['learning_rate'])\n        model.compile(optimizer=optimizer, loss='mean_squared_error')\n        \n        history = model.fit(\n            X_train_full, y_train_full,\n            validation_data=(X_test, y_test),\n            epochs=epochs,\n            batch_size=params['batch_size'],\n            verbose=0\n        )\n        \n        y_pred = model.predict(X_test)\n        y_pred_inv = scaler.inverse_transform(y_pred)\n        y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n        mse = mean_squared_error(y_test_inv, y_pred_inv)\n        \n        if mse &lt; best_mse:\n            best_mse = mse\n            best_params = params\n            best_model = model\n            best_y_pred = y_pred\n    \n    best_params_dict[col] = best_params\n    print(f\"Best parameters for {col}: {best_params} with MSE: {best_mse}\")\n    \n    models[col] = best_model\n    predictions[col] = {'Best Model': best_y_pred}\n    \n    # Inverting the normalization\n    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n    y_pred_inv = scaler.inverse_transform(best_y_pred)\n    \n    # Calculating MSE\n    mse_results[col] = {'Best Model': best_mse}\n    \n    # Visualization of results\n    plt.figure(figsize=(10, 4))\n    plt.plot(y_test_inv, label='Actual Value')\n    plt.plot(y_pred_inv, label='Prediction')\n    plt.title(f'Prediction vs Actual - {col} - Best Model')\n    plt.legend()\n    plt.savefig(os.path.join(report_dir, f'pred_vs_actual_{col}_Best_Model.png'))\n    plt.close()\n    \n    # Residual Analysis\n    residuals = y_test_inv - y_pred_inv\n    \n    # Plotting residuals\n    plt.figure(figsize=(10, 4))\n    plt.plot(residuals, label='Residuals')\n    plt.title(f'Residuals - {col} - Best Model')\n    plt.legend()\n    plt.savefig(os.path.join(report_dir, f'residuals_{col}_Best_Model.png'))\n    plt.close()\n    \n    # Ljung-Box test for autocorrelation in residuals\n    lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)\n    lb_pvalue = lb_test['lb_pvalue'].values[0]\n    \n    # Plotting residuals ACF\n    fig, ax = plt.subplots(figsize=(10, 4))\n    sm.graphics.tsa.plot_acf(residuals.squeeze(), lags=40, ax=ax)\n    plt.title(f'Residuals Autocorrelation Function - {col}')\n    plt.savefig(os.path.join(report_dir, f'acf_residuals_{col}_Best_Model.png'))\n    plt.close()\n    \n    # Heteroscedasticity test (Breusch-Pagan Test)\n    exog = sm.add_constant(best_model.predict(X_test))\n    test_bp = het_breuschpagan(residuals, exog)\n    bp_pvalue = test_bp[3]\n    \n    # Convert p-values to Python float\n    lb_pvalue = float(lb_pvalue)\n    bp_pvalue = float(bp_pvalue)\n    \n    # Saving statistical test results\n    residuals_analysis[col] = {\n        'residuals': residuals.flatten().tolist(),\n        'ljung_box_pvalue': lb_pvalue,\n        'breusch_pagan_pvalue': bp_pvalue\n    }\n    \n    print(f\"Residual Analysis for {col}:\")\n    print(f\"Ljung-Box Test p-value: {lb_pvalue}\")\n    print(f\"Breusch-Pagan Test p-value: {bp_pvalue}\")\n\n# Displaying final results in a table\nprint(\"\\nFinal Results:\")\nresults_table = pd.DataFrame(mse_results)\nprint(results_table)\n\n\n\nProcessing column: GF=F\nSeries GF=F has 2538 data points.\nPerforming Grid Search for GF=F...\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 116ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 116ms/step 2/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 119ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 128ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 122ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 119ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 104ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 128ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 119ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 137ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 132ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 114ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\nBest parameters for GF=F: {'activation': 'tanh', 'batch_size': 64, 'learning_rate': 0.01, 'neurons': 50} with MSE: 0.00010975314203772284\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step \nResidual Analysis for GF=F:\nLjung-Box Test p-value: 0.6580650350440331\nBreusch-Pagan Test p-value: 0.49401740958827367\n\nProcessing column: KE=F\nSeries KE=F has 2538 data points.\nPerforming Grid Search for KE=F...\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 121ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 143ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 1s 31ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 113ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 114ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 115ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 104ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 101ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 142ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 115ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 140ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 114ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 123ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\nBest parameters for KE=F: {'activation': 'tanh', 'batch_size': 32, 'learning_rate': 0.01, 'neurons': 50} with MSE: 0.0003824934060795627\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \nResidual Analysis for KE=F:\nLjung-Box Test p-value: 0.023936073373489828\nBreusch-Pagan Test p-value: 0.8645221705032164\n\nProcessing column: ZC=F\nSeries ZC=F has 2538 data points.\nPerforming Grid Search for ZC=F...\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 103ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 121ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 108ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 97ms/step 2/16 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 1s 42ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 126ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 144ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 118ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 118ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 126ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 110ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 110ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 127ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 128ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 127ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 145ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\nBest parameters for ZC=F: {'activation': 'tanh', 'batch_size': 32, 'learning_rate': 0.01, 'neurons': 30} with MSE: 0.00030591472594173485\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \nResidual Analysis for ZC=F:\nLjung-Box Test p-value: 1.3662608410957859e-08\nBreusch-Pagan Test p-value: 0.5912763297611698\n\nProcessing column: ZL=F\nSeries ZL=F has 2538 data points.\nPerforming Grid Search for ZL=F...\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 159ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 128ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 122ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 115ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 116ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 123ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 115ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 123ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 132ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 115ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\nBest parameters for ZL=F: {'activation': 'relu', 'batch_size': 64, 'learning_rate': 0.001, 'neurons': 50} with MSE: 0.00037011186539357647\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step \nResidual Analysis for ZL=F:\nLjung-Box Test p-value: 0.1356747836004889\nBreusch-Pagan Test p-value: 2.1591271527532874e-05\n\nProcessing column: ZM=F\nSeries ZM=F has 2538 data points.\nPerforming Grid Search for ZM=F...\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 123ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 128ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 119ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 127ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 123ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 125ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 130ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 133ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 130ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 113ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 120ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 107ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 135ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 113ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\nBest parameters for ZM=F: {'activation': 'tanh', 'batch_size': 32, 'learning_rate': 0.01, 'neurons': 30} with MSE: 0.00033008211850636443\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \nResidual Analysis for ZM=F:\nLjung-Box Test p-value: 0.19560805053383307\nBreusch-Pagan Test p-value: 0.8858028407446729\n\nProcessing column: ZR=F\nSeries ZR=F has 2538 data points.\nPerforming Grid Search for ZR=F...\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 115ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 113ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 127ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 124ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 128ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 124ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 114ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 119ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 119ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 161ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 115ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 127ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\nBest parameters for ZR=F: {'activation': 'tanh', 'batch_size': 64, 'learning_rate': 0.001, 'neurons': 50} with MSE: 0.13320168891741718\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \nResidual Analysis for ZR=F:\nLjung-Box Test p-value: 3.418023995173331e-08\nBreusch-Pagan Test p-value: 1.9375930920630364e-06\n\nProcessing column: ZS=F\nSeries ZS=F has 2538 data points.\nPerforming Grid Search for ZS=F...\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 120ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 129ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 126ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 125ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 127ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 117ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 123ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 4s 268ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 177ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 146ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 148ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 119ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 136ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step\nBest parameters for ZS=F: {'activation': 'tanh', 'batch_size': 32, 'learning_rate': 0.01, 'neurons': 50} with MSE: 0.0001521905867240005\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \nResidual Analysis for ZS=F:\nLjung-Box Test p-value: 0.11230267667017263\nBreusch-Pagan Test p-value: 0.24613617524870657\n\nProcessing column: ZW=F\nSeries ZW=F has 2538 data points.\nPerforming Grid Search for ZW=F...\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 2s 152ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 80ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 124ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 78ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 95ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 96ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 92ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 77ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 97ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 93ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 85ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 79ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 100ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 1s 83ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step\nBest parameters for ZW=F: {'activation': 'tanh', 'batch_size': 32, 'learning_rate': 0.01, 'neurons': 30} with MSE: 0.0004047325172525737\n 1/16 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \nResidual Analysis for ZW=F:\nLjung-Box Test p-value: 0.03766269738398695\nBreusch-Pagan Test p-value: 0.9953619829618164\n\nFinal Results:\n               GF=F      KE=F      ZC=F     ZL=F     ZM=F      ZR=F      ZS=F  \\\nBest Model  0.00011  0.000382  0.000306  0.00037  0.00033  0.133202  0.000152   \n\n                ZW=F  \nBest Model  0.000405  \n\n\nSaving the results in a table:\n\n\nCode\n# Saving results to a CSV file\nresults_table.to_csv(os.path.join(report_dir, 'mse_results_updated.csv'), index=True)\n\n# Saving the best parameters found\nwith open(os.path.join(report_dir, 'best_params.json'), 'w') as f:\n    json.dump(best_params_dict, f, indent=4)\n\n# Saving the residual analysis\nwith open(os.path.join(report_dir, 'residuals_analysis.json'), 'w') as f:\n    json.dump(residuals_analysis, f, indent=4)\n\n\nPloting the MSEs for each time series:\n\n\nCode\n# Report: Documenting the results\n# Plotting the MSEs for each time series\nfor col in mse_results.keys():\n    mse_series = mse_results[col]\n    plt.figure(figsize=(10, 5))\n    plt.bar(mse_series.keys(), mse_series.values(), color='blue')\n    plt.title(f'MSE Comparison - {col}')\n    plt.ylabel('MSE')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig(os.path.join(report_dir, f'mse_comparison_{col}.png'))\n    plt.close()\n\n\nSaving system info:\n\n\nCode\n# End timer\nend_time = datetime.now()\nelapsed_time = end_time - start_time  # This is a timedelta object\nprint(f\"Total execution time: {elapsed_time}\")\n\n# Save execution time to the report\nsystem_info['Execution_Time_seconds'] = elapsed_time.total_seconds()  # Convert to float for JSON\nwith open(os.path.join(report_dir, 'system_info.json'), 'w') as f:\n    json.dump(system_info, f, indent=4)\n\n\nTotal execution time: 0:06:42.996155\n\n\nGenerating an automatic final report:\n\n\nCode\n# Final Report: Generating a text document with the results\nreport_path = os.path.join(report_dir, 'final_report.txt')\nwith open(report_path, 'w') as report_file:\n    report_file.write(\"Final Project Report - Forecasting Commodity Returns with LSTM\\n\")\n    report_file.write(\"=\"*80 + \"\\n\\n\")\n    \n    report_file.write(\"1. Project Objectives:\\n\")\n    report_file.write(\"Forecast future returns of a commodity portfolio using LSTM Neural Networks.\\n\\n\")\n    \n    report_file.write(\"2. Methodology:\\n\")\n    report_file.write(\"- Collecting commodity price data.\\n\")\n    report_file.write(\"- Calculating logarithmic returns.\\n\")\n    report_file.write(\"- Normalizing the data.\\n\")\n    report_file.write(\"- Training LSTM models with different configurations.\\n\")\n    report_file.write(\"- Performing grid search to optimize hyperparameters.\\n\")\n    report_file.write(\"- Conducting residual analysis to identify uncaptured patterns and issues like autocorrelation or heteroscedasticity.\\n\\n\")\n    \n    report_file.write(\"3. Results:\\n\")\n    report_file.write(results_table.to_string())\n    report_file.write(\"\\n\\n\")\n    \n    report_file.write(\"4. Best Parameters Found (Grid Search):\\n\")\n    report_file.write(json.dumps(best_params_dict, indent=4))\n    report_file.write(\"\\n\\n\")\n    \n    report_file.write(\"5. Residual Analysis:\\n\")\n    for col, res in residuals_analysis.items():\n        report_file.write(f\"Residual Analysis for {col}:\\n\")\n        report_file.write(f\"Ljung-Box Test p-value: {res['ljung_box_pvalue']}\\n\")\n        report_file.write(f\"Breusch-Pagan Test p-value: {res['breusch_pagan_pvalue']}\\n\\n\")\n    report_file.write(\"\\n\")\n    \n    report_file.write(\"6. Conclusions:\\n\")\n    report_file.write(\"The study demonstrated the importance of proper hyperparameter selection and model architecture for forecasting financial returns. Regularization techniques and the choice of activation function significantly influenced model performance. The residual analysis highlighted the need to consider autocorrelation and heteroscedasticity in modeling financial time series.\\n\\n\")\n    \n    report_file.write(\"7. Recommendations for Future Work:\\n\")\n    report_file.write(\"- Implement additional regularization techniques, such as DropConnect or Batch Normalization.\\n\")\n    report_file.write(\"- Explore more advanced architectures, like GRU or bidirectional models.\\n\")\n    report_file.write(\"- Increase the dataset to improve the models' generalization capacity.\\n\")\n    report_file.write(\"- Use more robust cross-validation methods to assess model stability.\\n\")\n    report_file.write(\"- Integrate other features, such as technical indicators or macroeconomic variables, to enrich model inputs.\\n\")\n    report_file.write(\"- Consider hybrid models that combine Machine Learning techniques with traditional statistical models.\\n\")\n    \n    report_file.write(\"\\nSystem Information and Execution Time:\\n\")\n    report_file.write(json.dumps(system_info, indent=4))\n    report_file.write(\"\\n\\n\")\n    \n    report_file.write(\"End of Report.\\n\")",
    "crumbs": [
      "About",
      "Predictive Models"
    ]
  },
  {
    "objectID": "resmindmap.html",
    "href": "resmindmap.html",
    "title": "Research proposal",
    "section": "",
    "text": "Advanced Techniques for Multiperiod Multiobjective Portfolio Optimization in Agricultural Commodity Markets:\nCombining Volatility Modeling and Reinforcement Learning and Exploring Strategic Asset Allocation",
    "crumbs": [
      "About",
      "Intro",
      "Research proposal"
    ]
  },
  {
    "objectID": "resmindmap.html#mindmap",
    "href": "resmindmap.html#mindmap",
    "title": "Research proposal",
    "section": "MindMap",
    "text": "MindMap\n\nAdvanced Techniques for Multiperiod Multiobjective Portfolio Optimization in Agricultural Commodity Markets:\nCombining Volatility Modeling and Reinforcement Learning and Exploring Strategic Asset Allocation",
    "crumbs": [
      "About",
      "Intro",
      "Research proposal"
    ]
  }
]