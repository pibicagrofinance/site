# Passo 1: Baixar dados históricos e salvar em arquivos CSV
for (ticker in tickers) {
cat("Baixando dados para:", ticker, "\n")
# Tentar obter os dados do Yahoo Finance
tryCatch({
data_env <- new.env()
getSymbols(ticker, src = "yahoo", from = start_date, to = end_date, env = data_env, auto.assign = TRUE)
# Extrair os dados do ambiente e verificar o tipo
data <- data_env[[ticker]]
# Verificar se os dados são do tipo xts
if (is.xts(data)) {
# Converter para data frame e incluir a coluna Date
data <- data.frame(Date = index(data), coredata(data))
# Remover prefixos do ticker nos nomes das colunas
colnames(data) <- gsub(paste0("^", gsub("=F", "", ticker), "\\."), "", colnames(data))
# Selecionar apenas as colunas necessárias
required_columns <- c("Date", "Open", "High", "Low", "Close", "Volume", "Adjusted")
data <- data[, colnames(data) %in% required_columns, drop = FALSE]
# Verificar se a coluna 'Adjusted' existe, se não, criar a partir de 'Close'
if (!"Adjusted" %in% colnames(data)) {
data$Adjusted <- data$Close
}
# Garantir que todas as colunas necessárias estejam presentes
missing_cols <- setdiff(required_columns, colnames(data))
for (col in missing_cols) {
data[[col]] <- NA
}
# Selecionar as colunas na ordem correta
data <- data[required_columns]
# Remover linhas com valores ausentes
data <- na.omit(data)
# Renomear 'Adjusted' para 'Adj.Close'
colnames(data)[colnames(data) == "Adjusted"] <- "Adj.Close"
# Salvar em CSV
write.csv(data, file = paste0("data/", ticker, "_data.csv"), row.names = FALSE)
} else {
cat("Erro: Dados para", ticker, "não estão no formato esperado (xts).\n")
}
}, error = function(e) {
cat("Erro ao baixar os dados para:", ticker, "\n")
cat("Erro:", conditionMessage(e), "\n")
})
}
# Passo 2: Ler os arquivos CSV usando vroom
file_list <- list.files("data", pattern = "*_data.csv", full.names = TRUE)
combined_data <- vroom(file_list, id = "source", col_types = cols(
Date = col_date(),
Open = col_double(),
High = col_double(),
Low = col_double(),
Close = col_double(),
Volume = col_double(),
Adj.Close = col_double()
))
# Carregar os pacotes necessários
library(vroom)
library(plotly)
library(quantmod)
library(dplyr)
# Definir os tickers das commodities e o período de tempo
tickers <- c(
"ZC=F", # Corn Futures
"ZO=F", # Wheat Futures
"KE=F", # KC HRW Wheat Futures
"ZR=F", # Rough Rice Futures
"GF=F", # Feeder Cattle Futures
"ZS=F", # Soybean Meal Futures
"ZM=F", # Soybean Futures
"ZL=F"  # Soybean Oil Futures
)
start_date <- as.Date("2000-01-01")
end_date <- Sys.Date()
# Diretório para salvar os arquivos CSV
dir.create("data", showWarnings = FALSE)
# Passo 1: Baixar dados históricos e salvar em arquivos CSV
for (ticker in tickers) {
cat("Baixando dados para:", ticker, "\n")
# Tentar obter os dados do Yahoo Finance
tryCatch({
data_env <- new.env()
getSymbols(ticker, src = "yahoo", from = start_date, to = end_date, env = data_env, auto.assign = TRUE)
# Extrair os dados do ambiente e verificar o tipo
data <- data_env[[ticker]]
# Verificar se os dados são do tipo xts
if (is.xts(data)) {
# Converter para data frame e incluir a coluna Date
data <- data.frame(Date = index(data), coredata(data))
# Remover prefixos do ticker nos nomes das colunas
colnames(data) <- gsub(paste0("^", gsub("=F", "", ticker), "\\."), "", colnames(data))
# Selecionar apenas as colunas necessárias
required_columns <- c("Date", "Open", "High", "Low", "Close", "Volume", "Adjusted")
data <- data[, colnames(data) %in% required_columns, drop = FALSE]
# Verificar se a coluna 'Adjusted' existe, se não, criar a partir de 'Close'
if (!"Adjusted" %in% colnames(data)) {
data$Adjusted <- data$Close
}
# Garantir que todas as colunas necessárias estejam presentes
missing_cols <- setdiff(required_columns, colnames(data))
for (col in missing_cols) {
data[[col]] <- NA
}
# Selecionar as colunas na ordem correta
data <- data[required_columns]
# Remover linhas com valores ausentes
data <- na.omit(data)
# Renomear 'Adjusted' para 'Adj.Close'
colnames(data)[colnames(data) == "Adjusted"] <- "Adj.Close"
# Salvar em CSV
write.csv(data, file = paste0("data/", ticker, "_data.csv"), row.names = FALSE)
} else {
cat("Erro: Dados para", ticker, "não estão no formato esperado (xts).\n")
}
}, error = function(e) {
cat("Erro ao baixar os dados para:", ticker, "\n")
cat("Erro:", conditionMessage(e), "\n")
})
}
# Passo 2: Ler os arquivos CSV e padronizar colunas antes de combinar
file_list <- list.files("data", pattern = "*_data.csv", full.names = TRUE)
# Função para garantir que todos os arquivos tenham as colunas necessárias
standardize_columns <- function(file) {
data <- read.csv(file)
# Garantir que todas as colunas necessárias estejam presentes
required_columns <- c("Date", "Open", "High", "Low", "Close", "Volume", "Adj.Close")
missing_cols <- setdiff(required_columns, colnames(data))
# Adicionar as colunas ausentes com NA
for (col in missing_cols) {
data[[col]] <- NA
}
# Selecionar as colunas na ordem correta
data <- data[required_columns]
return(data)
}
# Aplicar a padronização e combinar todos os arquivos
combined_data_list <- lapply(file_list, standardize_columns)
combined_data <- do.call(rbind, combined_data_list)
# Converter a coluna Date para o tipo Date
combined_data$Date <- as.Date(combined_data$Date)
# Filtrar os dados para os últimos 12 meses
last_year_date <- Sys.Date() - 365
data_last_year <- combined_data %>% filter(Date >= last_year_date)
# Calcular a média de fechamento ajustado para cada commodity nos últimos 12 meses
average_close <- data_last_year %>%
group_by(Ticker) %>%
summarise(Average_Close = mean(Adj.Close, na.rm = TRUE))
# Carregar os pacotes necessários
library(vroom)
library(plotly)
library(quantmod)
library(dplyr)
# Definir os tickers das commodities e o período de tempo
tickers <- c(
"ZC=F", # Corn Futures
"ZO=F", # Wheat Futures
"KE=F", # KC HRW Wheat Futures
"ZR=F", # Rough Rice Futures
"GF=F", # Feeder Cattle Futures
"ZS=F", # Soybean Meal Futures
"ZM=F", # Soybean Futures
"ZL=F"  # Soybean Oil Futures
)
start_date <- as.Date("2000-01-01")
end_date <- Sys.Date()
# Diretório para salvar os arquivos CSV
dir.create("data", showWarnings = FALSE)
# Passo 1: Baixar dados históricos e salvar em arquivos CSV
for (ticker in tickers) {
cat("Baixando dados para:", ticker, "\n")
# Tentar obter os dados do Yahoo Finance
tryCatch({
data_env <- new.env()
getSymbols(ticker, src = "yahoo", from = start_date, to = end_date, env = data_env, auto.assign = TRUE)
# Extrair os dados do ambiente e verificar o tipo
data <- data_env[[ticker]]
# Verificar se os dados são do tipo xts
if (is.xts(data)) {
# Converter para data frame e incluir a coluna Date
data <- data.frame(Date = index(data), coredata(data))
# Remover prefixos do ticker nos nomes das colunas
colnames(data) <- gsub(paste0("^", gsub("=F", "", ticker), "\\."), "", colnames(data))
# Selecionar apenas as colunas necessárias
required_columns <- c("Date", "Open", "High", "Low", "Close", "Volume", "Adjusted")
data <- data[, colnames(data) %in% required_columns, drop = FALSE]
# Verificar se a coluna 'Adjusted' existe, se não, criar a partir de 'Close'
if (!"Adjusted" %in% colnames(data)) {
data$Adjusted <- data$Close
}
# Garantir que todas as colunas necessárias estejam presentes
missing_cols <- setdiff(required_columns, colnames(data))
for (col in missing_cols) {
data[[col]] <- NA
}
# Selecionar as colunas na ordem correta
data <- data[required_columns]
# Adicionar a coluna 'Ticker' ao data frame
data$Ticker <- ticker
# Remover linhas com valores ausentes
data <- na.omit(data)
# Renomear 'Adjusted' para 'Adj.Close'
colnames(data)[colnames(data) == "Adjusted"] <- "Adj.Close"
# Salvar em CSV
write.csv(data, file = paste0("data/", ticker, "_data.csv"), row.names = FALSE)
} else {
cat("Erro: Dados para", ticker, "não estão no formato esperado (xts).\n")
}
}, error = function(e) {
cat("Erro ao baixar os dados para:", ticker, "\n")
cat("Erro:", conditionMessage(e), "\n")
})
}
# Passo 2: Ler os arquivos CSV e padronizar colunas antes de combinar
file_list <- list.files("data", pattern = "*_data.csv", full.names = TRUE)
# Função para garantir que todos os arquivos tenham as colunas necessárias
standardize_columns <- function(file) {
data <- read.csv(file)
# Garantir que todas as colunas necessárias estejam presentes
required_columns <- c("Date", "Open", "High", "Low", "Close", "Volume", "Adj.Close", "Ticker")
missing_cols <- setdiff(required_columns, colnames(data))
# Adicionar as colunas ausentes com NA
for (col in missing_cols) {
data[[col]] <- NA
}
# Selecionar as colunas na ordem correta
data <- data[required_columns]
return(data)
}
# Aplicar a padronização e combinar todos os arquivos
combined_data_list <- lapply(file_list, standardize_columns)
combined_data <- do.call(rbind, combined_data_list)
# Converter a coluna Date para o tipo Date
combined_data$Date <- as.Date(combined_data$Date)
# Filtrar os dados para os últimos 12 meses
last_year_date <- Sys.Date() - 365
data_last_year <- combined_data %>% filter(Date >= last_year_date)
# Calcular a média de fechamento ajustado para cada commodity nos últimos 12 meses
average_close <- data_last_year %>%
group_by(Ticker) %>%
summarise(Average_Close = mean(Adj.Close, na.rm = TRUE))
print("Média do preço de fechamento ajustado nos últimos 12 meses:")
print(average_close)
# Calcular retornos diários usando o preço de fechamento ajustado
data_last_year <- data_last_year %>%
group_by(Ticker) %>%
arrange(Date) %>%
mutate(Return = Adj.Close / lag(Adj.Close) - 1)
# Calcular volatilidade (desvio padrão dos retornos) para cada commodity nos últimos 12 meses
volatility <- data_last_year %>%
group_by(Ticker) %>%
summarise(Volatility = sd(Return, na.rm = TRUE))
print("Volatilidade dos retornos nos últimos 12 meses:")
print(volatility)
# Gráfico interativo dos preços de fechamento ajustados
price_plot <- data_last_year %>%
plot_ly(x = ~Date, y = ~Adj.Close, color = ~Ticker, type = 'scatter', mode = 'lines') %>%
layout(title = "Preços de Fechamento Ajustados - Últimos 12 Meses",
xaxis = list(title = "Data"),
yaxis = list(title = "Preço de Fechamento Ajustado (USD)"))
# Gráfico interativo dos retornos
return_plot <- data_last_year %>%
plot_ly(x = ~Date, y = ~Return, color = ~Ticker, type = 'scatter', mode = 'lines') %>%
layout(title = "Retornos Diários - Últimos 12 Meses",
xaxis = list(title = "Data"),
yaxis = list(title = "Retorno Diário"))
# Gráfico de volatilidade (gráfico de barras)
volatility_plot <- volatility %>%
plot_ly(x = ~Ticker, y = ~Volatility, type = 'bar', color = ~Ticker) %>%
layout(title = "Volatilidade dos Retornos - Últimos 12 Meses",
xaxis = list(title = "Ticker"),
yaxis = list(title = "Volatilidade"))
# Exibir os gráficos
print(price_plot)
print(return_plot)
# Carregar os pacotes necessários
library(vroom)
library(plotly)
library(quantmod)
library(dplyr)
# Definir os tickers das commodities e o período de tempo
tickers <- c(
"ZC=F", # Corn Futures
"ZO=F", # Wheat Futures
"KE=F", # KC HRW Wheat Futures
"ZR=F", # Rough Rice Futures
"GF=F", # Feeder Cattle Futures
"ZS=F", # Soybean Meal Futures
"ZM=F", # Soybean Futures
"ZL=F"  # Soybean Oil Futures
)
start_date <- as.Date("2000-01-01")
end_date <- Sys.Date()
# Diretório para salvar os arquivos CSV
dir.create("data", showWarnings = FALSE)
# Passo 1: Baixar dados históricos e salvar em arquivos CSV
for (ticker in tickers) {
cat("Baixando dados para:", ticker, "\n")
# Tentar obter os dados do Yahoo Finance
tryCatch({
data_env <- new.env()
getSymbols(ticker, src = "yahoo", from = start_date, to = end_date, env = data_env, auto.assign = TRUE)
# Extrair os dados do ambiente e verificar o tipo
data <- data_env[[ticker]]
# Verificar se os dados são do tipo xts
if (is.xts(data)) {
# Converter para data frame e incluir a coluna Date
data <- data.frame(Date = index(data), coredata(data))
# Remover prefixos do ticker nos nomes das colunas
colnames(data) <- gsub(paste0("^", gsub("=F", "", ticker), "\\."), "", colnames(data))
# Selecionar apenas as colunas necessárias
required_columns <- c("Date", "Open", "High", "Low", "Close", "Volume", "Adjusted")
data <- data[, colnames(data) %in% required_columns, drop = FALSE]
# Verificar se a coluna 'Adjusted' existe, se não, criar a partir de 'Close'
if (!"Adjusted" %in% colnames(data)) {
data$Adjusted <- data$Close
}
# Garantir que todas as colunas necessárias estejam presentes
missing_cols <- setdiff(required_columns, colnames(data))
for (col in missing_cols) {
data[[col]] <- NA
}
# Selecionar as colunas na ordem correta
data <- data[required_columns]
# Adicionar a coluna 'Ticker' ao data frame
data$Ticker <- ticker
# Remover linhas com valores ausentes
data <- na.omit(data)
# Renomear 'Adjusted' para 'Adj.Close'
colnames(data)[colnames(data) == "Adjusted"] <- "Adj.Close"
# Salvar em CSV
write.csv(data, file = paste0("data/", ticker, "_data.csv"), row.names = FALSE)
} else {
cat("Erro: Dados para", ticker, "não estão no formato esperado (xts).\n")
}
}, error = function(e) {
cat("Erro ao baixar os dados para:", ticker, "\n")
cat("Erro:", conditionMessage(e), "\n")
})
}
# Passo 2: Ler os arquivos CSV e padronizar colunas antes de combinar
file_list <- list.files("data", pattern = "*_data.csv", full.names = TRUE)
# Função para garantir que todos os arquivos tenham as colunas necessárias
standardize_columns <- function(file) {
data <- read.csv(file)
# Extrair o ticker do nome do arquivo e adicionar ao data frame
data$Ticker <- sub("data/(.*)_data.csv", "\\1", file)
# Garantir que todas as colunas necessárias estejam presentes
required_columns <- c("Date", "Open", "High", "Low", "Close", "Volume", "Adj.Close", "Ticker")
missing_cols <- setdiff(required_columns, colnames(data))
# Adicionar as colunas ausentes com NA
for (col in missing_cols) {
data[[col]] <- NA
}
# Selecionar as colunas na ordem correta
data <- data[required_columns]
return(data)
}
# Aplicar a padronização e combinar todos os arquivos
combined_data_list <- lapply(file_list, standardize_columns)
combined_data <- do.call(rbind, combined_data_list)
# Converter a coluna Date para o tipo Date
combined_data$Date <- as.Date(combined_data$Date)
# Filtrar os dados para os últimos 12 meses
last_year_date <- Sys.Date() - 365
data_last_year <- combined_data %>% filter(Date >= last_year_date)
# Calcular a média de fechamento ajustado para cada commodity nos últimos 12 meses
average_close <- data_last_year %>%
group_by(Ticker) %>%
summarise(Average_Close = mean(Adj.Close, na.rm = TRUE))
print("Média do preço de fechamento ajustado nos últimos 12 meses:")
print(average_close)
# Calcular retornos diários usando o preço de fechamento ajustado
data_last_year <- data_last_year %>%
group_by(Ticker) %>%
arrange(Date) %>%
mutate(Return = Adj.Close / lag(Adj.Close) - 1)
# Calcular volatilidade (desvio padrão dos retornos) para cada commodity nos últimos 12 meses
volatility <- data_last_year %>%
group_by(Ticker) %>%
summarise(Volatility = sd(Return, na.rm = TRUE))
print("Volatilidade dos retornos nos últimos 12 meses:")
print(volatility)
# Gráfico interativo dos preços de fechamento ajustados
price_plot <- data_last_year %>%
plot_ly(x = ~Date, y = ~Adj.Close, color = ~Ticker, type = 'scatter', mode = 'lines') %>%
layout(title = "Preços de Fechamento Ajustados - Últimos 12 Meses",
xaxis = list(title = "Data"),
yaxis = list(title = "Preço de Fechamento Ajustado (USD)"))
# Gráfico interativo dos retornos
return_plot <- data_last_year %>%
plot_ly(x = ~Date, y = ~Return, color = ~Ticker, type = 'scatter', mode = 'lines') %>%
layout(title = "Retornos Diários - Últimos 12 Meses",
xaxis = list(title = "Data"),
yaxis = list(title = "Retorno Diário"))
# Gráfico de volatilidade (gráfico de barras)
volatility_plot <- volatility %>%
plot_ly(x = ~Ticker, y = ~Volatility, type = 'bar', color = ~Ticker) %>%
layout(title = "Volatilidade dos Retornos - Últimos 12 Meses",
xaxis = list(title = "Ticker"),
yaxis = list(title = "Volatilidade"))
# Exibir os gráficos
print(price_plot)
print(return_plot)
print(volatility_plot)
# Instalar pacotes necessários
if (!requireNamespace("sparklyr", quietly = TRUE)) install.packages("sparklyr")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
if (!requireNamespace("quantmod", quietly = TRUE)) install.packages("quantmod")
if (!requireNamespace("PerformanceAnalytics", quietly = TRUE)) install.packages("PerformanceAnalytics")
if (!requireNamespace("DBI", quietly = TRUE)) install.packages("DBI")
library(sparklyr)
library(dplyr)
library(ggplot2)
library(quantmod)
library(PerformanceAnalytics)
# Configuração do Spark
if (Sys.getenv("DATABRICKS_RUNTIME_VERSION") != "") {
# Conexão com Spark no Databricks
sc <- spark_connect(method = "databricks")
message("Conectado ao Spark no ambiente Databricks")
} else {
# Configuração local
sc <- spark_connect(master = "local")
message("Conectado ao Spark no ambiente local")
}
# Instalar pacotes necessários
if (!requireNamespace("sparklyr", quietly = TRUE)) install.packages("sparklyr")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
if (!requireNamespace("quantmod", quietly = TRUE)) install.packages("quantmod")
if (!requireNamespace("PerformanceAnalytics", quietly = TRUE)) install.packages("PerformanceAnalytics")
if (!requireNamespace("DBI", quietly = TRUE)) install.packages("DBI")
library(sparklyr)
library(dplyr)
library(ggplot2)
library(quantmod)
library(PerformanceAnalytics)
# Configuração do Spark
if (Sys.getenv("DATABRICKS_RUNTIME_VERSION") != "") {
# Conexão com Spark no Databricks
sc <- spark_connect(method = "databricks")
message("Conectado ao Spark no ambiente Databricks")
} else {
# Configuração local
sc <- spark_connect(master = "local")
message("Conectado ao Spark no ambiente local")
}
Sys.getenv("JAVA_HOME")
spark_install(version = "3.4.1")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_431")
# Instalar pacotes necessários
if (!requireNamespace("sparklyr", quietly = TRUE)) install.packages("sparklyr")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
if (!requireNamespace("quantmod", quietly = TRUE)) install.packages("quantmod")
if (!requireNamespace("PerformanceAnalytics", quietly = TRUE)) install.packages("PerformanceAnalytics")
if (!requireNamespace("DBI", quietly = TRUE)) install.packages("DBI")
library(sparklyr)
library(dplyr)
library(ggplot2)
library(quantmod)
library(PerformanceAnalytics)
# Configuração do Spark
if (Sys.getenv("DATABRICKS_RUNTIME_VERSION") != "") {
# Conexão com Spark no Databricks
sc <- spark_connect(method = "databricks")
message("Conectado ao Spark no ambiente Databricks")
} else {
# Configuração local
sc <- spark_connect(master = "local")
message("Conectado ao Spark no ambiente local")
}
Sys.getenv("JAVA_HOME")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_431")
library(sparklyr)
sc <- spark_connect(master = "local")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_431")
system("java -version")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_431")
system("java -version")
Sys.getenv("JAVA_HOME")
system("java -version")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_431")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_431")
system("java -version")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_411")
system("java -version")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_411")
system("java -version")
library(sparklyr)
sc <- spark_connect(master = "local")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_411")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_411")
system("java -version")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk1.8.0_411")
system("java -version")
spark_install()
devtools::install_github("rstudio/sparklyr")
library(sparklyr)
sc <- spark_connect(master = "local")
library(sparklyr)
spark_install(version = "3.0.0")
sc <- spark_connect(master = 'local')
install.packages("rsparkling")
library(rsparkling)
sc <- spark_connect(master = "local")
library(sparklyr)
spark_install()
sc <- spark_connect(master = "local")
devtools::install_github("sparklyr/sparklyr")
devtools::install_github("sparklyr/sparklyr", force = TRUE)
sparklyr::spark_connect(master="local")
sparklyr::spark_connect(master = "local")
