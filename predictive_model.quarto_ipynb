{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Final Project: Time Series Forecasting with LSTMs, Neural Networks Eng. Class\"\n",
        "subtitle: \"prof. Victor H. Alves Ribeiro, PPGEPS/PUCPR\"\n",
        "format:\n",
        "  html:\n",
        "    self-contained: true\n",
        "    toc: true\n",
        "    code-fold: true\n",
        "    df-print: paged\n",
        "editor: visual\n",
        "---"
      ],
      "id": "302502f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# #| eval: false\n",
        "\n",
        "# Start timer\n",
        "from datetime import datetime\n",
        "start_time = datetime.now()"
      ],
      "id": "765428ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "<left> ![](https://raw.githubusercontent.com/rhozon/Doutorado/main/pucpr_logo.png){width=\"10%\"} </left>\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "::: {.callout-note icon=\"false\"}\n",
        "\n",
        "\n",
        "Chamada do exercicio em ingles vai aqui\n",
        "\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "# Abstract\n",
        "\n",
        "This project aims to predict the returns of a selected portfolio of agricultural commodities using Long Short-Term Memory (LSTM) neural networks. The study includes ablation experiments to understand the impact of different architectural choices on model performance. The results demonstrate the importance of hyperparameter tuning and regularization in time series forecasting tasks.\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "The use of Artificial Neural Networks (ANNs) for time series forecasting has gained significant traction in recent years. This project focuses on utilizing LSTMs, a type of recurrent neural network capable of handling sequential data efficiently, to predict financial returns of agricultural commodities. A detailed ablation study is conducted to explore various architectural configurations and hyperparameters.\n",
        "\n",
        "\n",
        "\n",
        "# Literature Review\n",
        "\n",
        "Time series forecasting is critical in finance and economics. Traditional models, such as ARIMA and exponential smoothing, have limitations when dealing with non-linear and complex data. Recent studies emphasize the robustness of LSTM models in capturing temporal dependencies. This project builds on existing research by applying LSTM networks to a unique dataset of agricultural commodity returns.\n",
        "\n",
        "...see the full paper for this complete section ...\n",
        "\n",
        "# Methods\n",
        "\n",
        "- Collecting commodity price data.\n",
        "- Calculating logarithmic returns.\n",
        "- Normalizing the data.\n",
        "- Training LSTM models with different configurations.\n",
        "- Performing grid search to optimize hyperparameters.\n",
        "- Conducting residual analysis to identify uncaptured patterns and issues like autocorrelation or heteroscedasticity.\n",
        "\n",
        "# Results discussion\n",
        "\n",
        "## Data Collection and Preprocessing\n",
        "\n",
        "Python libs\n"
      ],
      "id": "6bf883b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import psutil\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Additional libraries for residual analysis\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox, het_breuschpagan\n",
        "import statsmodels.api as sm"
      ],
      "id": "44087ea4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First of all, we need to check the hardware availability:\n"
      ],
      "id": "bf63c3e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Collecting hardware information\n",
        "def get_system_info():\n",
        "    system_info = {\n",
        "        'CPU_cores': psutil.cpu_count(logical=True),\n",
        "        'CPU_freq_MHz': psutil.cpu_freq().current,\n",
        "        'Total_RAM_GB': round(psutil.virtual_memory().total / (1024 ** 3), 2),\n",
        "        'Available_RAM_GB': round(psutil.virtual_memory().available / (1024 ** 3), 2),\n",
        "        'GPU_info': 'Not available'  # Placeholder, can be expanded with libraries like GPUtil\n",
        "    }\n",
        "    return system_info\n",
        "\n",
        "system_info = get_system_info()\n",
        "print(\"System Information:\", system_info)"
      ],
      "id": "56b80bcf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading data:\n"
      ],
      "id": "27b89e2a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Defining the tickers\n",
        "tickers = [\n",
        "    \"ZC=F\",  # Corn Futures\n",
        "    \"ZW=F\",  # Wheat Futures\n",
        "    \"KE=F\",  # KC HRW Wheat Futures\n",
        "    \"ZR=F\",  # Rough Rice Futures\n",
        "    \"GF=F\",  # Feeder Cattle Futures\n",
        "    \"ZM=F\",  # Soybean Meal Futures\n",
        "    \"ZL=F\",  # Soybean Oil Futures\n",
        "    \"ZS=F\"   # Soybean Futures\n",
        "]\n",
        "\n",
        "# Downloading price data\n",
        "print(\"\\nDownloading price data...\")\n",
        "data = yf.download(tickers, start=\"2015-01-01\")['Close']\n",
        "\n",
        "# Handling missing data\n",
        "print(\"\\nHandling missing data...\")\n",
        "data.fillna(method='ffill', inplace=True)  # Forward fill\n",
        "data.dropna(axis=1, how='all', inplace=True)  # Drop columns with all NaNs\n",
        "data.dropna(axis=0, how='any', inplace=True)  # Drop rows with any NaNs\n",
        "\n",
        "# Verify data\n",
        "print(\"\\nData columns and their non-null counts:\")\n",
        "print(data.count())\n",
        "\n",
        "if data.empty:\n",
        "    print(\"Data is empty after cleaning. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "# Calculating logarithmic returns\n",
        "returns = np.log(data / data.shift(1)).dropna()\n",
        "\n",
        "# Verify returns\n",
        "print(\"\\nReturns DataFrame info:\")\n",
        "print(returns.info())\n",
        "print(returns.head())\n",
        "\n",
        "if returns.empty:\n",
        "    print(\"Returns DataFrame is empty. Exiting.\")\n",
        "    exit()\n",
        "    \n",
        "\n",
        "returns.head() # Showing time series used (without features)"
      ],
      "id": "06757848",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the time series of prices and returns side by side (2 per row)\n"
      ],
      "id": "de0bfcc9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a directory for plots if it doesn't exist\n",
        "plots_dir = 'plots'\n",
        "if not os.path.exists(plots_dir):\n",
        "    os.makedirs(plots_dir)\n",
        "\n",
        "# Plot prices\n",
        "print(\"\\nPlotting time series of prices...\")\n",
        "num_cols = 2  # Number of plots per row\n",
        "num_plots = len(data.columns)\n",
        "num_rows = (num_plots + num_cols - 1) // num_cols  # Ensure enough rows\n",
        "\n",
        "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, col in enumerate(data.columns):\n",
        "    axs[i].plot(data.index, data[col])\n",
        "    axs[i].set_title(f'Price Series - {col}')\n",
        "    axs[i].set_xlabel('Date')\n",
        "    axs[i].set_ylabel('Price')\n",
        "\n",
        "# Hide unused subplots\n",
        "for j in range(i + 1, len(axs)):\n",
        "    fig.delaxes(axs[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plots_dir, 'price_series.png'))\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# Plot returns\n",
        "print(\"Plotting time series of returns...\")\n",
        "num_plots_ret = len(returns.columns)\n",
        "num_rows_ret = (num_plots_ret + num_cols - 1) // num_cols\n",
        "\n",
        "fig, axs = plt.subplots(num_rows_ret, num_cols, figsize=(15, 5 * num_rows_ret))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, col in enumerate(returns.columns):\n",
        "    axs[i].plot(returns.index, returns[col])\n",
        "    axs[i].set_title(f'Return Series - {col}')\n",
        "    axs[i].set_xlabel('Date')\n",
        "    axs[i].set_ylabel('Log Return')\n",
        "\n",
        "# Hide unused subplots\n",
        "for j in range(i + 1, len(axs)):\n",
        "    fig.delaxes(axs[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plots_dir, 'return_series.png'))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "ffdc5ba8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessing data for LSTM time series modelling:\n"
      ],
      "id": "7c655a04"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to prepare data for LSTM\n",
        "def prepare_data(series, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(series) - time_steps):\n",
        "        X.append(series[i:(i + time_steps)])\n",
        "        y.append(series[i + time_steps])\n",
        "    return np.array(X), np.array(y)"
      ],
      "id": "baa8292a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting the parameters:\n"
      ],
      "id": "b3a849ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Defining parameters\n",
        "time_steps = 5  # Number of time steps\n",
        "epochs = 10  # Reduced epochs for faster execution during testing\n",
        "\n",
        "# Dictionaries to store results\n",
        "models = {}\n",
        "histories = {}\n",
        "mse_results = {}\n",
        "scalers = {}\n",
        "predictions = {}\n",
        "best_params_dict = {}\n",
        "residuals_analysis = {}\n",
        "\n",
        "# Directory to save reports and graphs\n",
        "report_dir = 'report'\n",
        "if not os.path.exists(report_dir):\n",
        "    os.makedirs(report_dir)"
      ],
      "id": "91a2ee6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM time series model fitting\n"
      ],
      "id": "e141b616"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Loop through each time series\n",
        "for col in returns.columns:\n",
        "    print(f\"\\nProcessing column: {col}\")\n",
        "    series = returns[col].values.reshape(-1, 1)\n",
        "    \n",
        "    # Check if series is empty\n",
        "    if len(series) == 0:\n",
        "        print(f\"Series {col} is empty after preprocessing. Skipping.\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"Series {col} has {len(series)} data points.\")\n",
        "    \n",
        "    # Normalizing data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    series_scaled = scaler.fit_transform(series)\n",
        "    scalers[col] = scaler  # Storing the scaler for later inversion\n",
        "    \n",
        "    # Preparing data\n",
        "    X, y = prepare_data(series_scaled, time_steps)\n",
        "    \n",
        "    # Check if X and y are non-empty\n",
        "    if X.shape[0] == 0:\n",
        "        print(f\"Not enough data points in {col} after preparation. Skipping.\")\n",
        "        continue\n",
        "    \n",
        "    # Splitting into training and test sets\n",
        "    split_index = int(0.8 * len(X))\n",
        "    X_train_full, X_test = X[:split_index], X[split_index:]\n",
        "    y_train_full, y_test = y[:split_index], y[split_index:]\n",
        "    X_train_full = X_train_full.reshape((X_train_full.shape[0], X_train_full.shape[1], 1))\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "    \n",
        "    # Hyperparameter grid for Grid Search\n",
        "    param_grid = {\n",
        "        'neurons': [30, 50],\n",
        "        'learning_rate': [0.001, 0.01],\n",
        "        'activation': ['tanh', 'relu'],\n",
        "        'batch_size': [32, 64]\n",
        "    }\n",
        "    grid = ParameterGrid(param_grid)\n",
        "    \n",
        "    # Initializing variables to store best results\n",
        "    best_mse = float('inf')\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "    \n",
        "    # Performing Grid Search\n",
        "    print(f\"Performing Grid Search for {col}...\")\n",
        "    for params in grid:\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(params['neurons'], activation=params['activation'], input_shape=(time_steps, 1)))\n",
        "        model.add(Dense(1))\n",
        "        optimizer = Adam(learning_rate=params['learning_rate'])\n",
        "        model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "        \n",
        "        history = model.fit(\n",
        "            X_train_full, y_train_full,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=epochs,\n",
        "            batch_size=params['batch_size'],\n",
        "            verbose=0\n",
        "        )\n",
        "        \n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_inv = scaler.inverse_transform(y_pred)\n",
        "        y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "        mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
        "        \n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_params = params\n",
        "            best_model = model\n",
        "            best_y_pred = y_pred\n",
        "    \n",
        "    best_params_dict[col] = best_params\n",
        "    print(f\"Best parameters for {col}: {best_params} with MSE: {best_mse}\")\n",
        "    \n",
        "    models[col] = best_model\n",
        "    predictions[col] = {'Best Model': best_y_pred}\n",
        "    \n",
        "    # Inverting the normalization\n",
        "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "    y_pred_inv = scaler.inverse_transform(best_y_pred)\n",
        "    \n",
        "    # Calculating MSE\n",
        "    mse_results[col] = {'Best Model': best_mse}\n",
        "    \n",
        "    # Visualization of results\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(y_test_inv, label='Actual Value')\n",
        "    plt.plot(y_pred_inv, label='Prediction')\n",
        "    plt.title(f'Prediction vs Actual - {col} - Best Model')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(report_dir, f'pred_vs_actual_{col}_Best_Model.png'))\n",
        "    plt.close()\n",
        "    \n",
        "    # Residual Analysis\n",
        "    residuals = y_test_inv - y_pred_inv\n",
        "    \n",
        "    # Plotting residuals\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(residuals, label='Residuals')\n",
        "    plt.title(f'Residuals - {col} - Best Model')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(report_dir, f'residuals_{col}_Best_Model.png'))\n",
        "    plt.close()\n",
        "    \n",
        "    # Ljung-Box test for autocorrelation in residuals\n",
        "    lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)\n",
        "    lb_pvalue = lb_test['lb_pvalue'].values[0]\n",
        "    \n",
        "    # Plotting residuals ACF\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    sm.graphics.tsa.plot_acf(residuals.squeeze(), lags=40, ax=ax)\n",
        "    plt.title(f'Residuals Autocorrelation Function - {col}')\n",
        "    plt.savefig(os.path.join(report_dir, f'acf_residuals_{col}_Best_Model.png'))\n",
        "    plt.close()\n",
        "    \n",
        "    # Heteroscedasticity test (Breusch-Pagan Test)\n",
        "    exog = sm.add_constant(best_model.predict(X_test))\n",
        "    test_bp = het_breuschpagan(residuals, exog)\n",
        "    bp_pvalue = test_bp[3]\n",
        "    \n",
        "    # Convert p-values to Python float\n",
        "    lb_pvalue = float(lb_pvalue)\n",
        "    bp_pvalue = float(bp_pvalue)\n",
        "    \n",
        "    # Saving statistical test results\n",
        "    residuals_analysis[col] = {\n",
        "        'residuals': residuals.flatten().tolist(),\n",
        "        'ljung_box_pvalue': lb_pvalue,\n",
        "        'breusch_pagan_pvalue': bp_pvalue\n",
        "    }\n",
        "    \n",
        "    print(f\"Residual Analysis for {col}:\")\n",
        "    print(f\"Ljung-Box Test p-value: {lb_pvalue}\")\n",
        "    print(f\"Breusch-Pagan Test p-value: {bp_pvalue}\")\n",
        "\n",
        "# Displaying final results in a table\n",
        "print(\"\\nFinal Results:\")\n",
        "results_table = pd.DataFrame(mse_results)\n",
        "print(results_table)"
      ],
      "id": "34139b8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the results in a table:\n"
      ],
      "id": "39722695"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Saving results to a CSV file\n",
        "results_table.to_csv(os.path.join(report_dir, 'mse_results_updated.csv'), index=True)\n",
        "\n",
        "# Saving the best parameters found\n",
        "with open(os.path.join(report_dir, 'best_params.json'), 'w') as f:\n",
        "    json.dump(best_params_dict, f, indent=4)\n",
        "\n",
        "# Saving the residual analysis\n",
        "with open(os.path.join(report_dir, 'residuals_analysis.json'), 'w') as f:\n",
        "    json.dump(residuals_analysis, f, indent=4)\n"
      ],
      "id": "4a70583a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ploting the MSEs for each time series:\n"
      ],
      "id": "8c9efe5e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Report: Documenting the results\n",
        "# Plotting the MSEs for each time series\n",
        "for col in mse_results.keys():\n",
        "    mse_series = mse_results[col]\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(mse_series.keys(), mse_series.values(), color='blue')\n",
        "    plt.title(f'MSE Comparison - {col}')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(report_dir, f'mse_comparison_{col}.png'))\n",
        "    plt.close()\n"
      ],
      "id": "5a15baef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving system info:\n"
      ],
      "id": "af92d284"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# End timer\n",
        "end_time = datetime.now()\n",
        "elapsed_time = end_time - start_time  # This is a timedelta object\n",
        "print(f\"Total execution time: {elapsed_time}\")\n",
        "\n",
        "# Save execution time to the report\n",
        "system_info['Execution_Time_seconds'] = elapsed_time.total_seconds()  # Convert to float for JSON\n",
        "with open(os.path.join(report_dir, 'system_info.json'), 'w') as f:\n",
        "    json.dump(system_info, f, indent=4)\n"
      ],
      "id": "3955ca24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generating an automatic final report:\n"
      ],
      "id": "dbf300eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final Report: Generating a text document with the results\n",
        "report_path = os.path.join(report_dir, 'final_report.txt')\n",
        "with open(report_path, 'w') as report_file:\n",
        "    report_file.write(\"Final Project Report - Forecasting Commodity Returns with LSTM\\n\")\n",
        "    report_file.write(\"=\"*80 + \"\\n\\n\")\n",
        "    \n",
        "    report_file.write(\"1. Project Objectives:\\n\")\n",
        "    report_file.write(\"Forecast future returns of a commodity portfolio using LSTM Neural Networks.\\n\\n\")\n",
        "    \n",
        "    report_file.write(\"2. Methodology:\\n\")\n",
        "    report_file.write(\"- Collecting commodity price data.\\n\")\n",
        "    report_file.write(\"- Calculating logarithmic returns.\\n\")\n",
        "    report_file.write(\"- Normalizing the data.\\n\")\n",
        "    report_file.write(\"- Training LSTM models with different configurations.\\n\")\n",
        "    report_file.write(\"- Performing grid search to optimize hyperparameters.\\n\")\n",
        "    report_file.write(\"- Conducting residual analysis to identify uncaptured patterns and issues like autocorrelation or heteroscedasticity.\\n\\n\")\n",
        "    \n",
        "    report_file.write(\"3. Results:\\n\")\n",
        "    report_file.write(results_table.to_string())\n",
        "    report_file.write(\"\\n\\n\")\n",
        "    \n",
        "    report_file.write(\"4. Best Parameters Found (Grid Search):\\n\")\n",
        "    report_file.write(json.dumps(best_params_dict, indent=4))\n",
        "    report_file.write(\"\\n\\n\")\n",
        "    \n",
        "    report_file.write(\"5. Residual Analysis:\\n\")\n",
        "    for col, res in residuals_analysis.items():\n",
        "        report_file.write(f\"Residual Analysis for {col}:\\n\")\n",
        "        report_file.write(f\"Ljung-Box Test p-value: {res['ljung_box_pvalue']}\\n\")\n",
        "        report_file.write(f\"Breusch-Pagan Test p-value: {res['breusch_pagan_pvalue']}\\n\\n\")\n",
        "    report_file.write(\"\\n\")\n",
        "    \n",
        "    report_file.write(\"6. Conclusions:\\n\")\n",
        "    report_file.write(\"The study demonstrated the importance of proper hyperparameter selection and model architecture for forecasting financial returns. Regularization techniques and the choice of activation function significantly influenced model performance. The residual analysis highlighted the need to consider autocorrelation and heteroscedasticity in modeling financial time series.\\n\\n\")\n",
        "    \n",
        "    report_file.write(\"7. Recommendations for Future Work:\\n\")\n",
        "    report_file.write(\"- Implement additional regularization techniques, such as DropConnect or Batch Normalization.\\n\")\n",
        "    report_file.write(\"- Explore more advanced architectures, like GRU or bidirectional models.\\n\")\n",
        "    report_file.write(\"- Increase the dataset to improve the models' generalization capacity.\\n\")\n",
        "    report_file.write(\"- Use more robust cross-validation methods to assess model stability.\\n\")\n",
        "    report_file.write(\"- Integrate other features, such as technical indicators or macroeconomic variables, to enrich model inputs.\\n\")\n",
        "    report_file.write(\"- Consider hybrid models that combine Machine Learning techniques with traditional statistical models.\\n\")\n",
        "    \n",
        "    report_file.write(\"\\nSystem Information and Execution Time:\\n\")\n",
        "    report_file.write(json.dumps(system_info, indent=4))\n",
        "    report_file.write(\"\\n\\n\")\n",
        "    \n",
        "    report_file.write(\"End of Report.\\n\")\n"
      ],
      "id": "d3859e62",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results and Discussion\n",
        "\n",
        "We begin reading the stored results by MSEs:\n"
      ],
      "id": "82dc40ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reading the stored results\n",
        "\n",
        "# 1. Reading the MSE results file\n",
        "# Define the report directory\n",
        "report_dir = 'report'\n",
        "\n",
        "# Path to the MSE results file\n",
        "mse_results_path = os.path.join(report_dir, 'mse_results_updated.csv')\n",
        "\n",
        "# Read the CSV file\n",
        "mse_results = pd.read_csv(mse_results_path, index_col=0)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"\\nMSE Results of the models:\")\n",
        "print(mse_results)"
      ],
      "id": "ddca3bdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we go to the best hyperparametes file for each time series univariate modelling: \n"
      ],
      "id": "133fb8f6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2. Reading the best parameters file\n",
        "# Path to the best parameters file\n",
        "best_params_path = os.path.join(report_dir, 'best_params.json')\n",
        "\n",
        "# Read the JSON file\n",
        "with open(best_params_path, 'r') as f:\n",
        "    best_params = json.load(f)\n",
        "\n",
        "# Display the best parameters\n",
        "print(\"\\nBest parameters found for each time series:\")\n",
        "for series, params in best_params.items():\n",
        "    print(f\"{series}: {params}\")\n"
      ],
      "id": "101f1213",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then we read the final report:\n"
      ],
      "id": "116b872b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3. Reading the final report\n",
        "# Path to the final report\n",
        "report_path = os.path.join(report_dir, 'final_report.txt')\n",
        "\n",
        "# Read the report\n",
        "with open(report_path, 'r') as report_file:\n",
        "    report_content = report_file.read()\n",
        "\n",
        "# Display the report\n",
        "print(\"\\nFinal Report Content:\")\n",
        "print(report_content)"
      ],
      "id": "3280ab34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the end we read the graphs for MSEs:\n"
      ],
      "id": "f728204b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 4. Viewing the graphs\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# List of time series\n",
        "series_list = returns.columns\n",
        "\n",
        "# Display MSE comparison graphs\n",
        "for col in series_list:\n",
        "    image_path = os.path.join(report_dir, f'mse_comparison_{col}.png')\n",
        "    if os.path.exists(image_path):\n",
        "        display(Image(filename=image_path))\n",
        "    else:\n",
        "        print(f\"Graph {image_path} not found.\")\n",
        "\n",
        "# Display residuals graphs\n",
        "for col in series_list:\n",
        "    residuals_image_path = os.path.join(report_dir, f'residuals_{col}_Best_Model.png')\n",
        "    acf_image_path = os.path.join(report_dir, f'acf_residuals_{col}_Best_Model.png')\n",
        "    if os.path.exists(residuals_image_path):\n",
        "        display(Image(filename=residuals_image_path))\n",
        "    else:\n",
        "        print(f\"Graph {residuals_image_path} not found.\")\n",
        "    if os.path.exists(acf_image_path):\n",
        "        display(Image(filename=acf_image_path))\n",
        "    else:\n",
        "        print(f\"Graph {acf_image_path} not found.\")\n",
        "\n",
        "# End of code"
      ],
      "id": "8a46b76c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "\n",
        "***\n",
        "\n",
        "# References\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "------------------------------------------------------------------------\n"
      ],
      "id": "6f40f5ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##| eval: false\n",
        "# Total timing to compile this Quarto document\n",
        "\n",
        "end_time = datetime.now()\n",
        "time_diff = end_time - start_time\n",
        "\n",
        "print(f\"Total Quarto document compiling time: {time_diff}\")"
      ],
      "id": "9c7fa0f6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python312\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}